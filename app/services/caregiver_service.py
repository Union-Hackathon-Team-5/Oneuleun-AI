import asyncio
import json
import logging
import time
from typing import Dict, List, Optional
from datetime import datetime

from app.models.caregiver_models import (
    CaregiverFriendlyResponse, StatusOverview, TodaySummary, KeyConcern,
    ActionPlan, UrgentAction, DetailedAnalysis, TrendAnalysis, TrendChange,
    UIComponents, QuickStat, CTAButton, EmotionTimeline, VideoHighlight,
    RiskIndicator, AudioAnalysis, ConversationTopic, EvidenceVisualization,
    MedicalDisclaimer
)
from app.services.analysis_service import AnalysisService
from app.models.analysis_models import ComprehensiveAnalysisResult

logger = logging.getLogger(__name__)


class CaregiverService:
    """ë³´í˜¸ì ì¹œí™”ì  ë¶„ì„ ê²°ê³¼ ìƒì„± ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.analysis_service = AnalysisService()
    
    async def generate_caregiver_friendly_report(
        self,
        conversation: str,
        image_analysis: Dict,
        audio_analysis: Dict,
        session_id: str,
        user_id: str,
        historical_data: Optional[List[Dict]] = None
    ) -> CaregiverFriendlyResponse:
        """ë³´í˜¸ì ì¹œí™”ì  ë¦¬í¬íŠ¸ ìƒì„±"""
        start_time = time.time()
        
        # ê¸°ì¡´ ê¸°ìˆ ì  ë¶„ì„ ì‹¤í–‰ (historical_data í¬í•¨)
        print(f"[PERF] Starting comprehensive_analysis", flush=True)
        logger.info("[PERF] Starting comprehensive_analysis")
        comp_start = time.time()
        comprehensive_analysis = await self.analysis_service.analyze_video_letter_comprehensive(
            conversation=conversation,
            image_analysis=image_analysis,
            historical_data=historical_data
        )
        comp_time = time.time() - comp_start
        print(f"[PERF] comprehensive_analysis completed in {comp_time:.2f}s", flush=True)
        logger.info(f"[PERF] comprehensive_analysis completed in {comp_time:.2f}s")
        
        # ê°ì„±ì , ì•¡ì…˜ ì¤‘ì‹¬ ë¦¬í¬íŠ¸ë¡œ ë³€í™˜
        print(f"[PERF] Starting _transform_to_caregiver_format", flush=True)
        logger.info("[PERF] Starting _transform_to_caregiver_format")
        transform_start = time.time()
        result = await self._transform_to_caregiver_format(
            comprehensive_analysis=comprehensive_analysis,
            conversation=conversation,
            image_analysis=image_analysis,
            audio_analysis=audio_analysis,
            session_id=session_id,
            user_id=user_id
        )
        transform_time = time.time() - transform_start
        total_time = time.time() - start_time
        print(f"[PERF] _transform_to_caregiver_format completed in {transform_time:.2f}s", flush=True)
        print(f"[PERF] Total time: {total_time:.2f}s", flush=True)
        logger.info(f"[PERF] _transform_to_caregiver_format completed in {transform_time:.2f}s")
        logger.info(f"[PERF] Total time: {total_time:.2f}s")
        
        return result
    
    async def _transform_to_caregiver_format(
        self,
        comprehensive_analysis: ComprehensiveAnalysisResult,
        conversation: str,
        image_analysis: Dict,
        audio_analysis: Dict,
        session_id: str,
        user_id: str
    ) -> CaregiverFriendlyResponse:
        """ê¸°ìˆ ì  ë¶„ì„ì„ ë³´í˜¸ì ì¹œí™”ì  í˜•íƒœë¡œ ë³€í™˜"""
        
        # ê°ì„±ì  ì¸ì‚¬ì´íŠ¸ ìƒì„± (ë³‘ë ¬ ì²˜ë¦¬, íƒ€ì„ì•„ì›ƒ ì ìš©)
        print(f"[PERF] Starting parallel LLM calls (4 tasks)", flush=True)
        logger.info("[PERF] Starting parallel LLM calls (4 tasks)")
        parallel_start = time.time()
        
        # ê° ì‘ì—…ì— íƒ€ì„ì•„ì›ƒ ë˜í¼ ì ìš© (15ì´ˆ)
        async def insights_with_timeout():
            try:
                return await asyncio.wait_for(
                    self._generate_emotional_insights(conversation, comprehensive_analysis),
                    timeout=15.0
                )
            except (asyncio.TimeoutError, Exception) as exc:
                logger.error(f"Emotional insights generation failed/timeout: {exc}")
                return {
                    "headline": "ì–´ë¨¸ë‹ˆ ìƒíƒœë¥¼ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤",
                    "mood_description": "í‰ì†Œë³´ë‹¤ ê¸°ë¶„ì´ ì¢‹ì§€ ì•Šìœ¼ì‹  ê²ƒ ê°™ì•„ìš”",
                    "energy_level": "í™œë ¥ì´ ë¶€ì¡±í•´ ë³´ì…ë‹ˆë‹¤",
                    "pain_level": "ëª¸ì´ ë¶ˆí¸í•˜ì‹  ê²ƒ ê°™ì•„ìš”",
                    "emotional_state": "ê´€ì‹¬ê³¼ ëŒë´„ì´ í•„ìš”í•œ ìƒíƒœì…ë‹ˆë‹¤"
                }
        
        async def action_plan_with_timeout():
            try:
                return await asyncio.wait_for(
                    self._generate_actionable_plan(comprehensive_analysis, conversation),
                    timeout=15.0
                )
            except (asyncio.TimeoutError, Exception) as exc:
                logger.error(f"Action plan generation failed/timeout: {exc}")
                return self._create_default_action_plan(comprehensive_analysis)
        
        async def mother_voice_with_timeout():
            try:
                return await asyncio.wait_for(
                    self._extract_mother_voice(conversation),
                    timeout=15.0
                )
            except (asyncio.TimeoutError, Exception) as exc:
                logger.error(f"Mother voice extraction failed/timeout: {exc}")
                return [
                    "ğŸ’¬ \"ìš”ì¦˜ ì»¨ë””ì…˜ì´ ë³„ë¡œ ì¢‹ì§€ ì•Šì•„ìš”\"",
                    "ğŸ’¬ \"í˜¼ì ìˆëŠ” ì‹œê°„ì´ ë§ì•„ì„œ ì™¸ë¡œì›Œìš”\"",
                    "ğŸ’¬ \"ëª¸ì´ ì˜ˆì „ ê°™ì§€ ì•Šì•„ì„œ ê±±ì •ì´ì—ìš”\""
                ]
        
        async def concerns_with_timeout():
            try:
                return await asyncio.wait_for(
                    self._identify_key_concerns(comprehensive_analysis, conversation, image_analysis),
                    timeout=15.0
                )
            except (asyncio.TimeoutError, Exception) as exc:
                logger.error(f"Key concerns identification failed/timeout: {exc}")
                return self._create_default_concerns(comprehensive_analysis)
        
        emotional_insights, action_plan, mother_voice, key_concerns = await asyncio.gather(
            insights_with_timeout(),
            action_plan_with_timeout(),
            mother_voice_with_timeout(),
            concerns_with_timeout()
        )
        parallel_time = time.time() - parallel_start
        print(f"[PERF] Parallel LLM calls completed in {parallel_time:.2f}s", flush=True)
        logger.info(f"[PERF] Parallel LLM calls completed in {parallel_time:.2f}s")
        
        # ë³‘ë ¬ LLM í˜¸ì¶œ ì´í›„ í›„ì²˜ë¦¬ ì‘ì—…ë“¤ ì‹œê°„ ì¸¡ì •
        post_process_start = time.time()
        
        # 1ìˆœìœ„: ìƒíƒœ ê°œìš” (key_concerns ìƒì„± í›„ì— ê²°ì •í•˜ì—¬ ì¼ê´€ì„± ë³´ì¥)
        status_overview = self._create_status_overview(comprehensive_analysis, key_concerns)
        
        # 2ìˆœìœ„: ì˜¤ëŠ˜ ìš”ì•½
        today_summary = self._create_today_summary(
            comprehensive_analysis, emotional_insights, mother_voice
        )
        
        # 3ìˆœìœ„: ì£¼ìš” ê±±ì •ê±°ë¦¬ (ì´ë¯¸ ìƒì„±ë¨)
        
        # 4ìˆœìœ„: í–‰ë™ ê³„íš (ì´ë¯¸ ìƒì„±ë¨)
        
        # 5ìˆœìœ„: ìƒì„¸ ë¶„ì„ (key_concernsì™€ ì¼ì¹˜ì‹œí‚´)
        detailed_analysis = self._create_detailed_analysis(
            comprehensive_analysis, conversation, audio_analysis, key_concerns
        )
        
        # Baseline ë¹„êµ ë°ì´í„° ìƒì„± (ì¶”ì„¸ ë¶„ì„ ì „ì— í•„ìš”)
        baseline_comparison = self._create_baseline_comparison(comprehensive_analysis)
        
        # 6ìˆœìœ„: ì¶”ì„¸ ë¶„ì„ (baseline ë¹„êµ ê¸°ë°˜ìœ¼ë¡œ í™œì„±í™”/ë¹„í™œì„±í™”)
        trend_analysis = self._create_trend_analysis(comprehensive_analysis, baseline_comparison)
        
        # UI ì»´í¬ë„ŒíŠ¸
        ui_components = self._create_ui_components(status_overview, comprehensive_analysis)
        
        # ê·¼ê±° ì‹œê°í™” ë°ì´í„° ìƒì„± (ë§¥ë½ ì¶©ëŒ ê°ì§€ í¬í•¨)
        evidence_viz = self._create_evidence_visualization(
            comprehensive_analysis, conversation, audio_analysis, image_analysis, key_concerns
        )
        
        # ì˜ë£Œ ì±…ì„ ë©´ì±… ì¡°í•­ ìƒì„± (action_planê³¼ ì¼ì¹˜ì‹œí‚´)
        medical_disclaimer = self._create_medical_disclaimer(comprehensive_analysis, action_plan, key_concerns)
        
        post_process_time = time.time() - post_process_start
        print(f"[PERF] Post-processing (data transformation) completed in {post_process_time:.2f}s", flush=True)
        
        return CaregiverFriendlyResponse(
            success=True,
            session_id=session_id,
            user_id=user_id,
            recorded_at=datetime.now().strftime("%Y-%m-%d %H:%M"),
            status_overview=status_overview,
            today_summary=today_summary,
            key_concerns=key_concerns,
            action_plan=action_plan,
            detailed_analysis=detailed_analysis,
            trend_analysis=trend_analysis,
            ui_components=ui_components,
            evidence_visualization=evidence_viz,
            baseline_comparison=baseline_comparison,
            medical_disclaimer=medical_disclaimer
        )
    
    async def _generate_emotional_insights(
        self, 
        conversation: str, 
        analysis: ComprehensiveAnalysisResult
    ) -> Dict:
        """ê°ì„±ì  ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        prompt = f"""
ë‹¤ìŒ ë…ê±°ë…¸ì¸ì˜ ëŒ€í™”ì—ì„œ ë³´í˜¸ìê°€ ì•Œì•„ì•¼ í•  ê°ì„±ì  í¬ì¸íŠ¸ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ëŒ€í™” ë‚´ìš©:
{conversation}

ë¶„ì„ ê²°ê³¼:
- ê°ì •: {analysis.emotion_analysis.overall_mood}
- ì£¼ìš” ìš°ë ¤: {analysis.comprehensive_summary.key_concerns}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "headline": "<ì–´ë¨¸ë‹ˆ ìƒíƒœë¥¼ í•œì¤„ë¡œ ìš”ì•½ (ê°ì„±ì ìœ¼ë¡œ)>",
    "mood_description": "<ê¸°ë¶„ ìƒíƒœë¥¼ ì¸ê°„ì ìœ¼ë¡œ ì„¤ëª…>",
    "energy_level": "<í™œë ¥ ìˆ˜ì¤€ ì„¤ëª…>",
    "pain_level": "<í†µì¦ ìˆ˜ì¤€ ì„¤ëª…>",
    "emotional_state": "<ì „ë°˜ì  ê°ì • ìƒíƒœ>"
}}

ì˜ˆì‹œ:
- "ì–´ë¨¸ë‹ˆê»˜ì„œ ë§ì´ í˜ë“¤ì–´í•˜ì‹­ë‹ˆë‹¤"
- "í‰ì†Œë³´ë‹¤ ë§ì´ ì§€ì³ ë³´ì´ì„¸ìš”"
- "ì™¸ë¡œì›€ì„ ë§ì´ ëŠë¼ê³  ê³„ì‹  ê²ƒ ê°™ì•„ìš”"
"""
        
        try:
            task_start = time.time()
            response = await self.analysis_service._call_openai(prompt, max_tokens=500, task_name="_generate_emotional_insights")
            task_time = time.time() - task_start
            print(f"[PERF] _generate_emotional_insights API call: {task_time:.2f}s", flush=True)
            logger.debug(f"[PERF] _generate_emotional_insights API call: {task_time:.2f}s")
            return json.loads(response)
        except Exception as exc:
            logger.error("Failed to generate emotional insights: %s", exc)
            return {
                "headline": "ì–´ë¨¸ë‹ˆ ìƒíƒœë¥¼ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤",
                "mood_description": "í‰ì†Œë³´ë‹¤ ê¸°ë¶„ì´ ì¢‹ì§€ ì•Šìœ¼ì‹  ê²ƒ ê°™ì•„ìš”",
                "energy_level": "í™œë ¥ì´ ë¶€ì¡±í•´ ë³´ì…ë‹ˆë‹¤",
                "pain_level": "ëª¸ì´ ë¶ˆí¸í•˜ì‹  ê²ƒ ê°™ì•„ìš”",
                "emotional_state": "ê´€ì‹¬ê³¼ ëŒë´„ì´ í•„ìš”í•œ ìƒíƒœì…ë‹ˆë‹¤"
            }
    
    async def _generate_actionable_plan(
        self, 
        analysis: ComprehensiveAnalysisResult, 
        conversation: str
    ) -> ActionPlan:
        """ì‹¤í–‰ ê°€ëŠ¥í•œ í–‰ë™ ê³„íš ìƒì„± (ê³¼ë„í•œ ê²½ê³  ë°©ì§€)"""
        
        # baseline ë¹„êµ ì •ë³´ ì¶”ê°€
        baseline_context = ""
        if analysis.anomaly_analysis.baseline_comparisons:
            significant = [c for c in analysis.anomaly_analysis.baseline_comparisons if c.is_significant_change]
            if significant:
                baseline_context = f"\nê°œì¸ baseline ë¹„êµ: {len(significant)}ê°œì˜ ìœ ì˜ë¯¸í•œ ë³€í™” ê°ì§€"
        
        # í”„ë¡¬í”„íŠ¸ ê°„ì†Œí™”: í•µì‹¬ë§Œ í¬í•¨
        key_concerns_str = ", ".join(analysis.comprehensive_summary.key_concerns[:3]) if analysis.comprehensive_summary.key_concerns else "ì—†ìŒ"
        recommended_str = ", ".join(analysis.comprehensive_summary.recommended_actions[:3]) if analysis.comprehensive_summary.recommended_actions else "ì—†ìŒ"
        
        prompt = f"""ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ í–‰ë™ ê³„íš ìƒì„± (ê°„ê²°í•˜ê²Œ):

ëŒ€í™” ìš”ì•½: {conversation[:300]}...
ìœ„í—˜ë„: {analysis.comprehensive_summary.priority_level}
ì£¼ìš” ìš°ë ¤: {key_concerns_str}
ê¶Œì¥ ì¡°ì¹˜: {recommended_str}
{baseline_context}

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ (ê° ì¹´í…Œê³ ë¦¬ ìµœëŒ€ 3ê°œ):
{{
    "urgent_actions": [{{"action_id": 1, "priority": "ìµœìš°ì„ |ê¸´ê¸‰|ì¤‘ìš”", "icon": "ğŸ“", "title": "êµ¬ì²´ì  í–‰ë™", "reason": "ì´ìœ ", "detail": "ì–´ë¨¸ë‹ˆ ë§ì”€ ì¸ìš©", "deadline": "ì–¸ì œê¹Œì§€", "estimated_time": "ì†Œìš”ì‹œê°„", "suggested_topics": ["ëŒ€í™”ì˜ˆì‹œ1", "ëŒ€í™”ì˜ˆì‹œ2"]}}],
    "this_week_actions": [...],
    "long_term_actions": [...]
}}

ì£¼ì˜: urgent_actionsëŠ” ê¸´ê¸‰ì‹œ 1-2ê°œë§Œ. priorityëŠ” "ìµœìš°ì„ ", "ê¸´ê¸‰", "ì¤‘ìš”" ì¤‘ í•˜ë‚˜ë§Œ. ê±´ê°• ê´€ë ¨ì€ "ì˜ë£Œì§„ ìƒë‹´ ê¶Œì¥" í‘œí˜„ ì‚¬ìš©.
"""
        
        try:
            task_start = time.time()
            # max_tokensë¥¼ 600ìœ¼ë¡œ ì¤„ì„ (ì‹¤ì œë¡œëŠ” urgent 2ê°œ + this_week 3ê°œ + long_term 2ê°œ ì •ë„ë©´ ì¶©ë¶„)
            response = await self.analysis_service._call_openai(prompt, max_tokens=600, task_name="_generate_actionable_plan")
            task_time = time.time() - task_start
            print(f"[PERF] _generate_actionable_plan API call: {task_time:.2f}s", flush=True)
            logger.debug(f"[PERF] _generate_actionable_plan API call: {task_time:.2f}s")
            data = json.loads(response)
            
            # priority í•„ë“œ ê²€ì¦ ë° ê¸°ë³¸ê°’ ì²˜ë¦¬
            valid_priorities = ["ìµœìš°ì„ ", "ê¸´ê¸‰", "ì¤‘ìš”"]
            
            def normalize_action(action: Dict) -> Dict:
                """priority í•„ë“œ ì •ê·œí™”"""
                if "priority" in action:
                    priority = action["priority"]
                    if priority not in valid_priorities:
                        # ìœ íš¨í•˜ì§€ ì•Šì€ priorityë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ë³€ê²½
                        if priority in ["ë³´í†µ", "ë‚®ìŒ", "normal", "low"]:
                            action["priority"] = "ì¤‘ìš”"
                        elif priority in ["ë†’ìŒ", "high", "urgent"]:
                            action["priority"] = "ê¸´ê¸‰"
                        else:
                            action["priority"] = "ì¤‘ìš”"  # ê¸°ë³¸ê°’
                else:
                    action["priority"] = "ì¤‘ìš”"  # ê¸°ë³¸ê°’
                return action
            
            # Pydantic model_validateë¡œ ìµœì í™” (priority ì •ê·œí™” í›„)
            urgent_actions = [UrgentAction.model_validate(normalize_action(action)) for action in data.get("urgent_actions", [])]
            this_week_actions = [UrgentAction.model_validate(normalize_action(action)) for action in data.get("this_week_actions", [])]
            long_term_actions = [UrgentAction.model_validate(normalize_action(action)) for action in data.get("long_term_actions", [])]
            
            return ActionPlan(
                urgent_actions=urgent_actions,
                this_week_actions=this_week_actions,
                long_term_actions=long_term_actions
            )
        except Exception as exc:
            logger.error("Failed to generate action plan: %s", exc)
            return self._create_default_action_plan(analysis)
    
    async def _extract_mother_voice(self, conversation: str) -> List[str]:
        """ì–´ë¨¸ë‹ˆ ëª©ì†Œë¦¬ ì§ì ‘ ì¸ìš© ì¶”ì¶œ"""
        prompt = f"""
ë‹¤ìŒ ëŒ€í™”ì—ì„œ ë…ê±°ë…¸ì¸(ì–´ë¨¸ë‹ˆ)ì´ ì§ì ‘ í•˜ì‹  ë§ì”€ ì¤‘ì—ì„œ ë³´í˜¸ìê°€ ë“¤ìœ¼ë©´ ë§ˆìŒì´ ì•„í”„ê±°ë‚˜ ê±±ì •ì´ ë  ë§Œí•œ ë¶€ë¶„ì„ ì°¾ì•„ì„œ ì§ì ‘ ì¸ìš©í•´ì£¼ì„¸ìš”.

ëŒ€í™” ë‚´ìš©:
{conversation}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "mother_voice": [
        "ğŸ’¬ \\"ì‹¤ì œ ì–´ë¨¸ë‹ˆê°€ í•˜ì‹  ë§ì”€1\\"",
        "ğŸ’¬ \\"ì‹¤ì œ ì–´ë¨¸ë‹ˆê°€ í•˜ì‹  ë§ì”€2\\"",
        "ğŸ’¬ \\"ì‹¤ì œ ì–´ë¨¸ë‹ˆê°€ í•˜ì‹  ë§ì”€3\\"",
        "ğŸ’¬ \\"ì‹¤ì œ ì–´ë¨¸ë‹ˆê°€ í•˜ì‹  ë§ì”€4\\""
    ]
}}

ì˜ˆì‹œ:
- "ğŸ’¬ \"ìš”ì¦˜ì€ ìê¾¸ í”¼ê³¤í•´ì„œ ë­˜ í•´ë„ ê¸ˆë°© ì§€ì¹˜ëŠ” ëŠë‚Œì´ì—ìš”\""
- "ğŸ’¬ \"ë©°ì¹ ì§¸ ë°¥ë§›ì´ ì—†ê³  ì”¹ëŠ” ê²ƒë„ ì¢€ í˜ë“¤ì–´ì„œìš”\""
- "ğŸ’¬ \"ê³„ì† ì§‘ì—ë§Œ ìˆë‹¤ ë³´ë‹ˆê¹Œ ì‚¬ëŒ ëª©ì†Œë¦¬ê°€ ê·¸ë¦½ë„¤ìš”\""
"""
        
        try:
            task_start = time.time()
            response = await self.analysis_service._call_openai(prompt, max_tokens=400, task_name="_extract_mother_voice")
            task_time = time.time() - task_start
            print(f"[PERF] _extract_mother_voice API call: {task_time:.2f}s", flush=True)
            logger.debug(f"[PERF] _extract_mother_voice API call: {task_time:.2f}s")
            data = json.loads(response)
            return data.get("mother_voice", [])
        except Exception as exc:
            logger.error("Failed to extract mother voice: %s", exc)
            return [
                "ğŸ’¬ \"ìš”ì¦˜ ì»¨ë””ì…˜ì´ ë³„ë¡œ ì¢‹ì§€ ì•Šì•„ìš”\"",
                "ğŸ’¬ \"í˜¼ì ìˆëŠ” ì‹œê°„ì´ ë§ì•„ì„œ ì™¸ë¡œì›Œìš”\"",
                "ğŸ’¬ \"ëª¸ì´ ì˜ˆì „ ê°™ì§€ ì•Šì•„ì„œ ê±±ì •ì´ì—ìš”\""
            ]
    
    async def _identify_key_concerns(
        self, 
        analysis: ComprehensiveAnalysisResult, 
        conversation: str, 
        image_analysis: Dict
    ) -> List[KeyConcern]:
        """ì£¼ìš” ê±±ì •ê±°ë¦¬ ì‹ë³„ (ê°€ì¡± ì¼€ì–´ ì¡°ì–¸ í†¤)"""
        # ìœ„í—˜ ë¶„ì„ ì •ë³´ ê°„ì†Œí™”
        risk_level = analysis.risk_analysis.risk_level
        risk_keywords = ", ".join(analysis.risk_analysis.detected_keywords[:5])
        image_concerns = ", ".join(image_analysis.get('analysis', {}).get('concerns', [])[:3])
        
        prompt = f"""ì£¼ìš” ê±±ì •ê±°ë¦¬ ì‹ë³„ (ìµœëŒ€ 5ê°œ):

ëŒ€í™” ìš”ì•½: {conversation[:300]}...
ìœ„í—˜ë„: {risk_level}
ìœ„í—˜ í‚¤ì›Œë“œ: {risk_keywords}
ì´ë¯¸ì§€ ìš°ë ¤: {image_concerns or "ì—†ìŒ"}

JSON í˜•ì‹ (ê°„ê²°í•˜ê²Œ):
{{
    "concerns": [
        {{
            "concern_id": 1,
            "type": "ê±´ê°•|ì•ˆì „|ì •ì„œ|ìƒí™œ",
            "icon": "ğŸ¥",
            "severity": "urgent|caution|normal",
            "title": "êµ¬ì²´ì  ë¬¸ì œ",
            "description": "ê°€ì¡± ì¼€ì–´ ì¡°ì–¸ í†¤ìœ¼ë¡œ ê°„ë‹¨íˆ ì„¤ëª…",
            "detected_from": ["ëŒ€í™”", "í‘œì •"],
            "urgency_reason": "ì™œ ì¤‘ìš”í•œì§€"
        }}
    ]
}}

ì£¼ì˜: "ì˜ë£Œì§„ ìƒë‹´ ê¶Œì¥" í‘œí˜„ ì‚¬ìš©. "ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”" ê°™ì€ í‘œí˜„ í”¼í•˜ê¸°.
"""
        
        try:
            task_start = time.time()
            # max_tokensë¥¼ 500ìœ¼ë¡œ ì¤„ì„ (concernsëŠ” ë³´í†µ 3-5ê°œ, ê°ê° 100 tokens ì •ë„ë©´ ì¶©ë¶„)
            response = await self.analysis_service._call_openai(prompt, max_tokens=500, task_name="_identify_key_concerns")
            task_time = time.time() - task_start
            print(f"[PERF] _identify_key_concerns API call: {task_time:.2f}s", flush=True)
            logger.debug(f"[PERF] _identify_key_concerns API call: {task_time:.2f}s")
            data = json.loads(response)
            # Pydantic model_validateë¡œ ìµœì í™”
            return [KeyConcern.model_validate(concern) for concern in data.get("concerns", [])]
        except Exception as exc:
            logger.error("Failed to identify key concerns: %s", exc)
            return self._create_default_concerns(analysis)
    
    def _create_status_overview(self, analysis: ComprehensiveAnalysisResult, key_concerns: List[KeyConcern]) -> StatusOverview:
        """ìƒíƒœ ê°œìš” ìƒì„± (Alert level ì¼ê´€ì„± ë³´ì¥: ìµœê³  ìœ„í—˜ë„ ê¸°ì¤€)"""
        # ìµœê³  ìœ„í—˜ë„ ê¸°ì¤€ìœ¼ë¡œ ë‹¨ì¼í™” (key_concernsì˜ ìµœê³  severity ìš°ì„ )
        max_concern_severity = "normal"
        if key_concerns:
            # key_concernsì—ì„œ ìµœê³  severity ì°¾ê¸°
            severity_map = {"urgent": 3, "caution": 2, "normal": 1}
            max_severity_value = max(severity_map.get(concern.severity, 1) for concern in key_concerns)
            max_concern_severity = [k for k, v in severity_map.items() if v == max_severity_value][0]
        
        # baseline ë¹„êµë¥¼ ê³ ë ¤í•˜ì—¬ ê²½ê³  ê°•ë„ ì¡°ì ˆ
        has_significant_change = False
        if analysis.anomaly_analysis.baseline_comparisons:
            has_significant_change = any(
                comp.is_significant_change 
                for comp in analysis.anomaly_analysis.baseline_comparisons
            )
        
        # Alert level ê²°ì •: ìµœê³  ìœ„í—˜ë„ ê¸°ì¤€ìœ¼ë¡œ ë‹¨ì¼í™”
        # urgentê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ urgent
        if max_concern_severity == "urgent" or analysis.comprehensive_summary.priority_level == "ê¸´ê¸‰":
            return StatusOverview(
                alert_level="urgent",
                alert_badge="ğŸš¨",
                alert_title="ì¦‰ì‹œ í™•ì¸ í•„ìš”",
                alert_subtitle="ì–´ë¨¸ë‹ˆê»˜ì„œ ë„ì›€ì´ í•„ìš”í•˜ì‹  ê²ƒ ê°™ìŠµë‹ˆë‹¤",
                status_color="#FF4444"
            )
        elif max_concern_severity == "caution" or (analysis.comprehensive_summary.priority_level == "ì£¼ì˜" and has_significant_change):
            # ì£¼ì˜ëŠ” baseline ë³€í™”ê°€ ìˆì„ ë•Œë§Œ ê°•ì¡°
            return StatusOverview(
                alert_level="caution",
                alert_badge="âš ï¸",
                alert_title="í‰ì†Œì™€ ë‹¤ë¥¸ ì  í™•ì¸",
                alert_subtitle="ì§€ë‚œ 7ì¼ í‰ê·  ëŒ€ë¹„ ë³€í™”ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤",
                status_color="#FF8800"
            )
        elif analysis.comprehensive_summary.priority_level == "ì£¼ì˜":
            # ì£¼ì˜ì´ì§€ë§Œ baseline ë³€í™”ê°€ ì—†ìœ¼ë©´ ê²½ë¯¸í•˜ê²Œ í‘œì‹œ
            return StatusOverview(
                alert_level="normal",
                alert_badge="ğŸ“‹",
                alert_title="ì¼ë°˜ í™•ì¸ ê¶Œì¥",
                alert_subtitle="ì •ê¸°ì ìœ¼ë¡œ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”",
                status_color="#FFAA00"
            )
        else:
            return StatusOverview(
                alert_level="normal",
                alert_badge="ğŸ˜Š",
                alert_title="ì•ˆì •ì ì¸ ìƒíƒœ",
                alert_subtitle="íŠ¹ë³„í•œ ë¬¸ì œëŠ” ì—†ì–´ ë³´ì…ë‹ˆë‹¤",
                status_color="#44FF44"
            )
    
    def _create_today_summary(
        self, 
        analysis: ComprehensiveAnalysisResult, 
        emotional_insights: Dict,
        mother_voice: List[str]
    ) -> TodaySummary:
        """ì˜¤ëŠ˜ ìš”ì•½ ìƒì„± (Baseline ë¹„êµ í¬í•¨)"""
        mood_score = analysis.emotion_analysis.positive
        
        # Baseline ë¹„êµ ì •ë³´ ì¶”ì¶œ
        baseline_info = ""
        if analysis.anomaly_analysis.baseline_comparisons:
            for comp in analysis.anomaly_analysis.baseline_comparisons:
                if comp.metric == "ê¸ì • ê°ì •":
                    baseline_info = f" (í‰ì†Œ í‰ê·  {comp.baseline_average:.0f}ì  ëŒ€ë¹„ {comp.difference:+.0f}ì )"
                    break
        
        if mood_score >= 70:
            mood_label = f"ì¢‹ìŒ{baseline_info}" if baseline_info else "ì¢‹ìŒ"
            mood_emoji = "ğŸ˜Š"
        elif mood_score >= 50:
            mood_label = f"ë³´í†µ{baseline_info}" if baseline_info else "ë³´í†µ"
            mood_emoji = "ğŸ˜"
        elif mood_score >= 30:
            mood_label = f"ìš°ìš¸í•¨{baseline_info}" if baseline_info else "ìš°ìš¸í•¨"
            mood_emoji = "ğŸ˜”"
        else:
            mood_label = f"ë§¤ìš° ìš°ìš¸í•¨{baseline_info}" if baseline_info else "ë§¤ìš° ìš°ìš¸í•¨"
            mood_emoji = "ğŸ˜¢"
        
        # headline ê°œì„ : ê¸´ê¸‰ ê·¼ê±° ì¤‘ì‹¬ (ìš©ì–´Â·í†¤ ì¼ê´€ì„±)
        headline = emotional_insights.get("headline", "ì–´ë¨¸ë‹ˆ ìƒíƒœë¥¼ í™•ì¸í•´ë³´ì„¸ìš”")
        
        # ê¸´ê¸‰í•œ ê²½ìš°(urgent) ê±´ê°• ê´€ë ¨ êµ¬ì²´ì  ê·¼ê±°ë¥¼ headlineì— í¬í•¨
        if analysis.comprehensive_summary.priority_level == "ê¸´ê¸‰":
            urgent_health_issues = []
            health_str = str(analysis.risk_analysis.risk_categories.health)
            safety_str = str(analysis.risk_analysis.risk_categories.safety)
            
            if "ì‹ì‚¬" in health_str or "ë°¥" in health_str or "ìŒì‹" in health_str:
                urgent_health_issues.append("ì‹ì‚¬ëŸ‰ ê°ì†Œ")
            if "í†µì¦" in health_str or "ì•„íŒŒ" in health_str:
                urgent_health_issues.append("í†µì¦")
            if "ë‚™ìƒ" in safety_str:
                urgent_health_issues.append("ë‚™ìƒ ìœ„í—˜")
            
            if urgent_health_issues:
                headline = f"{', '.join(urgent_health_issues)}ê°€ ë™ë°˜ë˜ì–´ ì¦‰ì‹œ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤"
            else:
                headline = "ì¦‰ì‹œ í™•ì¸ì´ í•„ìš”í•œ ìƒíƒœì…ë‹ˆë‹¤"
        
        return TodaySummary(
            headline=headline,
            mood_score=mood_score,
            mood_label=mood_label,
            mood_emoji=mood_emoji,
            energy_score=max(0, 100 - analysis.emotion_analysis.depression),
            pain_score=analysis.emotion_analysis.anxiety,
            mother_voice=mother_voice[:4]  # ìµœëŒ€ 4ê°œ
        )
    
    def _create_detailed_analysis(
        self, 
        analysis: ComprehensiveAnalysisResult, 
        conversation: str,
        audio_analysis: Dict,
        key_concerns: List[KeyConcern]
    ) -> DetailedAnalysis:
        """ìƒì„¸ ë¶„ì„ ìƒì„±"""
        # ëŒ€í™” ì£¼ì œë³„ ìš”ì•½
        topics = []
        if "ì‹ì‚¬" in conversation or "ë°¥" in conversation:
            topics.append(ConversationTopic(
                topic="ì‹ì‚¬",
                summary="ì‹ìš• ê´€ë ¨ ì–¸ê¸‰ì´ ìˆìŠµë‹ˆë‹¤",
                concern_level="caution" if "ì•ˆ ë¨¹" in conversation else "normal"
            ))
        
        # ê°ì • íƒ€ì„ë¼ì¸ (ë”ë¯¸ ë°ì´í„°)
        emotion_timeline = [
            EmotionTimeline(
                timestamp="00:00:30",
                emotion="ë¬´ê¸°ë ¥",
                intensity=75,
                trigger="í”¼ê³¤í•˜ë‹¤ëŠ” ë§ì”€"
            )
        ]
        
        # ìœ„í—˜ ì§€í‘œ (R3: key_concernsì˜ ìµœëŒ€ severity ê¸°ì¤€)
        health_concerns = [c for c in key_concerns if c.type == "ê±´ê°•"]
        mental_concerns = [c for c in key_concerns if c.type == "ì •ì„œ"]
        
        # ìµœëŒ€ severity ì°¾ê¸°
        severity_map = {"urgent": 3, "caution": 2, "normal": 1}
        
        health_max_severity = "normal"
        if health_concerns:
            health_max_severity_value = max(severity_map.get(c.severity, 1) for c in health_concerns)
            health_max_severity = [k for k, v in severity_map.items() if v == health_max_severity_value][0]
        
        mental_max_severity = "normal"
        if mental_concerns:
            mental_max_severity_value = max(severity_map.get(c.severity, 1) for c in mental_concerns)
            mental_max_severity = [k for k, v in severity_map.items() if v == mental_max_severity_value][0]
        
        # severityë¥¼ levelë¡œ ë³€í™˜ (urgent/caution -> high, normal -> medium/low)
        health_level = "high" if health_max_severity == "urgent" else "medium" if health_max_severity == "caution" else "low"
        mental_level = "high" if mental_max_severity == "urgent" else "medium" if mental_max_severity == "caution" else "low"
        
        # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ì™€ ë³‘í•© (ë” ë†’ì€ ë ˆë²¨ ìš°ì„ )
        if analysis.comprehensive_summary.priority_level == "ê¸´ê¸‰" and health_level != "high":
            health_level = "high"
        if analysis.emotion_analysis.depression > 70 and mental_level != "high":
            mental_level = "high"
        
        risk_indicators = {
            "health_risk": RiskIndicator(
                level=health_level,
                factors=analysis.risk_analysis.risk_categories.health
            ),
            "mental_risk": RiskIndicator(
                level=mental_level,
                factors=analysis.risk_analysis.risk_categories.mental
            )
        }
        
        # ì˜ìƒ í•˜ì´ë¼ì´íŠ¸ (ë”ë¯¸)
        video_highlights = [
            VideoHighlight(
                timestamp="00:01:30",
                thumbnail_url="placeholder_thumbnail.jpg",
                emotion="ìš°ìš¸",
                caption="í‘œì •ì´ ì–´ë‘ì›Œ ë³´ì…ë‹ˆë‹¤",
                importance="high"
            )
        ]
        
        # ìŒì„± ë¶„ì„
        audio_analysis_obj = AudioAnalysis(
            voice_energy=audio_analysis.get("voice_energy", "ë³´í†µ"),
            speaking_pace=audio_analysis.get("speaking_pace", "ë³´í†µ"),
            tone_quality=audio_analysis.get("tone_quality", "ë³´í†µ"),
            emotional_indicators=audio_analysis.get("emotional_indicators", [])
        )
        
        return DetailedAnalysis(
            conversation_summary={
                "total_exchanges": len(conversation.split("\n")),
                "conversation_topics": [topic.dict() for topic in topics]
            },
            emotion_timeline=emotion_timeline,
            risk_indicators=risk_indicators,
            video_highlights=video_highlights,
            audio_analysis=audio_analysis_obj
        )
    
    def _create_trend_analysis(self, analysis: ComprehensiveAnalysisResult, baseline_comparison: Optional[Dict]) -> TrendAnalysis:
        """ì¶”ì„¸ ë¶„ì„ ìƒì„± (R5: 7ì¼ ë¯¸ë§Œì´ë©´ ë¹„í™œì„±í™”)"""
        # baseline_comparisonì´ ì—†ê±°ë‚˜ ë°ì´í„° ë¶€ì¡± ì‹œ ë¹„í™œì„±í™”
        if not baseline_comparison or baseline_comparison.get("comparison_period", "").endswith("ë°ì´í„° ë¶€ì¡±"):
            return TrendAnalysis(
                compared_to="ì§€ë‚œ 7ì¼",
                changes=[],
                alert_message="7ì¼ ë¯¸ë§Œ ë°ì´í„°ë¡œ ì‹ ë¢° ë‚®ìŒ",
                pattern="ë°ì´í„° ë¶€ì¡±",
                disabled=True,
                reason="7ì¼ ë¯¸ë§Œ ë°ì´í„°ë¡œ ì‹ ë¢° ë‚®ìŒ"
            )
        
        # baseline_comparisonì—ì„œ ì¶”ì„¸ ë°ì´í„° ìƒì„±
        significant_changes = baseline_comparison.get("significant_changes", [])
        changes = []
        
        for change in significant_changes[:5]:  # ìµœëŒ€ 5ê°œ
            direction = "down" if change.get("difference", 0) < 0 else "up" if change.get("difference", 0) > 0 else "stable"
            icon = "ğŸ“‰" if direction == "down" else "ğŸ“ˆ" if direction == "up" else "â¡ï¸"
            
            changes.append(TrendChange(
                metric=change.get("metric", ""),
                direction=direction,
                change=int(change.get("difference", 0)),
                icon=icon,
                comment=change.get("explanation", "")
            ))
        
        if not changes:
            # ìœ ì˜ë¯¸í•œ ë³€í™”ê°€ ì—†ìœ¼ë©´ ì•ˆì •ì  í‘œì‹œ
            return TrendAnalysis(
                compared_to="ì§€ë‚œ 7ì¼",
                changes=[],
                alert_message="ì§€ë‚œ 7ì¼ ëŒ€ë¹„ í° ë³€í™” ì—†ìŒ",
                pattern="ì•ˆì •ì "
            )
        
        alert_message = f"âš ï¸ ì§€ë‚œ 7ì¼ ëŒ€ë¹„ {len(changes)}ê°œì˜ ìœ ì˜ë¯¸í•œ ë³€í™”ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤"
        pattern = "ì§€ì†ì  í•˜ë½" if any(c.direction == "down" for c in changes) else "ì§€ì†ì  ìƒìŠ¹" if any(c.direction == "up" for c in changes) else "ë³€ë™"
        
        return TrendAnalysis(
            compared_to="ì§€ë‚œ 7ì¼",
            changes=changes,
            alert_message=alert_message,
            pattern=pattern
        )
    
    def _create_ui_components(
        self, 
        status: StatusOverview, 
        analysis: ComprehensiveAnalysisResult
    ) -> UIComponents:
        """UI ì»´í¬ë„ŒíŠ¸ ìƒì„±"""
        quick_stats = [
            QuickStat(
                label="ê¸°ë¶„",
                value=f"{analysis.emotion_analysis.positive}/100",
                emoji="ğŸ˜¢" if analysis.emotion_analysis.positive < 50 else "ğŸ˜Š",
                color=status.status_color
            ),
            QuickStat(
                label="í™œë ¥",
                value="ë‚®ìŒ" if analysis.emotion_analysis.depression > 50 else "ë³´í†µ",
                emoji="ğŸ˜´",
                color="#FF8800"
            )
        ]
        
        cta_buttons = [
            CTAButton(
                text="ì§€ê¸ˆ ì „í™”í•˜ê¸°",
                icon="ğŸ“",
                color="#FF4444",
                action="call"
            ),
            CTAButton(
                text="ì˜ìƒ ì „ì²´ë³´ê¸°",
                icon="ğŸ¬",
                color="#4444FF",
                action="watch_video"
            )
        ]
        
        if analysis.comprehensive_summary.priority_level == "ê¸´ê¸‰":
            cta_buttons.append(CTAButton(
                text="ë³‘ì› ì˜ˆì•½í•˜ê¸°",
                icon="ğŸ¥",
                color="#FF8800",
                action="book_hospital"
            ))
        
        return UIComponents(
            header={
                "badge_color": status.status_color,
                "badge_text": status.alert_title.split()[0],
                "title": status.alert_subtitle,
                "subtitle": f"ì˜¤ëŠ˜ {datetime.now().strftime('%H:%M')} ì´¬ì˜"
            },
            quick_stats=quick_stats,
            cta_buttons=cta_buttons
        )
    
    def _create_default_action_plan(self, analysis: ComprehensiveAnalysisResult) -> ActionPlan:
        """ê¸°ë³¸ í–‰ë™ ê³„íš ìƒì„±"""
        urgent_actions = [
            UrgentAction(
                action_id=1,
                priority="ìµœìš°ì„ ",
                icon="ğŸ“",
                title="ì–´ë¨¸ë‹ˆê»˜ ì•ˆë¶€ ì „í™” ë“œë¦¬ê¸°",
                reason="í˜„ì¬ ìƒíƒœ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤",
                detail="ì–´ë¨¸ë‹ˆê°€ ì—°ë½ì„ ê¸°ë‹¤ë¦¬ê³  ê³„ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤",
                deadline="ì˜¤ëŠ˜ ì¤‘",
                estimated_time="10-15ë¶„",
                suggested_topics=[
                    "ì—„ë§ˆ ì•ˆ ë°”ë¹ ìš”. ì–´ë”” ë¶ˆí¸í•˜ì‹  ë° ì—†ìœ¼ì„¸ìš”?",
                    "ì‹ì‚¬ëŠ” ì˜ í•˜ì„¸ìš”? ì œê°€ ë°˜ì°¬ ì¢€ ê°€ì ¸ë‹¤ ë“œë¦´ê²Œìš”",
                    "ì´ë²ˆ ì£¼ë§ì— ê°ˆê²Œìš”. ë­”ê°€ í•„ìš”í•œ ê±° ìˆìœ¼ì„¸ìš”?"
                ]
            )
        ]
        
        return ActionPlan(
            urgent_actions=urgent_actions,
            this_week_actions=[],
            long_term_actions=[]
        )
    
    def _create_default_concerns(self, analysis: ComprehensiveAnalysisResult) -> List[KeyConcern]:
        """ê¸°ë³¸ ê±±ì •ê±°ë¦¬ ìƒì„±"""
        concerns = []
        
        if analysis.emotion_analysis.depression > 70:
            concerns.append(KeyConcern(
                concern_id=1,
                type="ì •ì„œ",
                icon="ğŸ’”",
                severity="caution",
                title="ìš°ìš¸í•œ ê¸°ë¶„",
                description="í‰ì†Œë³´ë‹¤ ê¸°ë¶„ì´ ë§ì´ ê°€ë¼ì•‰ì•„ ìˆìœ¼ì‹  ê²ƒ ê°™ìŠµë‹ˆë‹¤. ê´€ì‹¬ì„ ë” ê¸°ìš¸ì—¬ì£¼ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤",
                detected_from=["ëŒ€í™”", "í‘œì •"],
                urgency_reason="ìš°ìš¸ê° ì•…í™” ê°€ëŠ¥ì„±"
            ))
        
        if analysis.emotion_analysis.loneliness > 70:
            concerns.append(KeyConcern(
                concern_id=2,
                type="ì •ì„œ",
                icon="ğŸ‘¥",
                severity="caution",
                title="ì™¸ë¡œì›€",
                description="í˜¼ì ê³„ì‹œëŠ” ì‹œê°„ì´ ë§ì•„ ì™¸ë¡œì›Œí•˜ì‹œëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤. ì´ë²ˆ ì£¼ë§ì— ì‹œê°„ ë‚´ì–´ ë°©ë¬¸í•´ì£¼ì‹œë©´ ì¢‹ê² ìŠµë‹ˆë‹¤",
                detected_from=["ëŒ€í™”"],
                urgency_reason="ì‚¬íšŒì  ê³ ë¦½ ìš°ë ¤"
            ))
        
        return concerns
    
    def _create_evidence_visualization(
        self,
        analysis: ComprehensiveAnalysisResult,
        conversation: str,
        audio_analysis: Dict,
        image_analysis: Dict,
        key_concerns: List[KeyConcern]
    ) -> EvidenceVisualization:
        """ê·¼ê±° ì‹œê°í™” ë°ì´í„° ìƒì„±"""
        emotion_evidence = analysis.emotion_analysis.evidence
        
        # ê°ì • í‚¤ì›Œë“œ ì¶”ì¶œ
        emotion_keywords = []
        keyword_weights = {}
        
        if emotion_evidence:
            all_keywords = emotion_evidence.detected_keywords
            emotion_keywords = all_keywords[:10]  # ìµœëŒ€ 10ê°œ
            
            # í‚¤ì›Œë“œë³„ ê°€ì¤‘ì¹˜ ê°œì„ : ë¹ˆë„Ã—ê°•ë„Ã—ìµœê·¼ì„± (R6)
            keyword_counts = {}
            for keyword in all_keywords:
                keyword_counts[keyword] = keyword_counts.get(keyword, 0) + 1
            
            # ê°ì • ê°•ë„ ë§¤í•‘ (ë†’ì„ìˆ˜ë¡ ì¤‘ìš”)
            emotion_intensity = {
                "ìš°ìš¸": 0.9, "ìŠ¬í””": 0.8, "ì™¸ë¡œì›€": 0.7, "ë¶ˆì•ˆ": 0.8, "ë¶„ë…¸": 0.7,
                "ë¬´ê¸°ë ¥": 0.6, "í”¼ê³¤": 0.5, "í–‰ë³µ": 0.3, "ê¸°ì¨": 0.3
            }
            
            # ê°€ì¤‘ì¹˜ ê³„ì‚°: ë¹ˆë„ Ã— ê°•ë„ (ìµœê·¼ì„±ì€ ì¼ë‹¨ ìƒëµ)
            raw_weights = {}
            for keyword, count in keyword_counts.items():
                intensity = emotion_intensity.get(keyword, 0.5)
                raw_weights[keyword] = count * intensity
            
            # Softmax ì •ê·œí™” (í•© = 1)
            total_weight = sum(raw_weights.values())
            if total_weight > 0:
                for keyword, weight in raw_weights.items():
                    keyword_weights[keyword] = weight / total_weight
            else:
                for keyword in all_keywords:
                    keyword_weights[keyword] = 1.0 / len(all_keywords) if all_keywords else 0.0
        
        # í‘œì • ë³€í™” íƒ€ì„ë¼ì¸ (ì‹ ë¢°ë„ ê¸°ì¤€ í•„í„°ë§)
        facial_timeline = []
        confidence_threshold = 60  # 60% ë¯¸ë§Œì´ë©´ ê°ì • ë¯¸ê²€ì¶œë¡œ ì²˜ë¦¬
        if image_analysis.get("analysis"):
            img_data = image_analysis["analysis"]
            emotions = img_data.get("emotion", [])
            confidence = image_analysis.get("confidence", 0)
            
            # confidenceê°€ ë‚®ìœ¼ë©´ ê°ì • ë¯¸ê²€ì¶œ ì²˜ë¦¬
            if confidence >= confidence_threshold and emotions:
                # í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°ì • ì¶”ì¶œ (ëŒ€í™” ë§¥ë½)
                text_emotions = set()
                if emotion_evidence and emotion_evidence.detected_keywords:
                    for kw in emotion_evidence.detected_keywords:
                        if "ìš°ìš¸" in kw or "ìŠ¬í””" in kw:
                            text_emotions.add("ìš°ìš¸")
                        elif "í”¼ê³¤" in kw or "ë¬´ê¸°ë ¥" in kw:
                            text_emotions.add("ë¬´ê¸°ë ¥")
                        elif "ì™¸ë¡œì›€" in kw:
                            text_emotions.add("ì™¸ë¡œì›€")
                        elif "ë¶„ë…¸" in kw or "í™”" in kw:
                            text_emotions.add("ë¶„ë…¸")
                
                for i, emotion in enumerate(emotions[:5]):  # ìµœëŒ€ 5ê°œ
                    # ê° ê°ì •ë³„ confidence ê³„ì‚° (ì „ì²´ confidenceë¥¼ ê¸°ë°˜ìœ¼ë¡œ)
                    emotion_confidence = max(confidence_threshold, confidence - (i * 5))
                    
                    # ë§¥ë½ ì¶©ëŒ ê°ì§€ (R4): í…ìŠ¤íŠ¸ì™€ í‘œì • ë¶ˆì¼ì¹˜ ì²´í¬
                    context_mismatch = False
                    if text_emotions and emotion not in text_emotions:
                        # ì˜ˆ: í‘œì •ì€ ë¶„ë…¸ì¸ë° í…ìŠ¤íŠ¸ëŠ” ìš°ìš¸/í”¼ê³¤
                        if emotion == "ë¶„ë…¸" and ("ìš°ìš¸" in text_emotions or "ë¬´ê¸°ë ¥" in text_emotions):
                            context_mismatch = True
                        elif emotion in ["ê¸°ì¨", "í–‰ë³µ"] and ("ìš°ìš¸" in text_emotions or "ì™¸ë¡œì›€" in text_emotions):
                            context_mismatch = True
                    
                    reliability = "ë†’ìŒ" if emotion_confidence >= 80 else "ë³´í†µ" if emotion_confidence >= 60 else "ë‚®ìŒ"
                    if context_mismatch:
                        reliability = "ë³´ë¥˜"
                    
                    facial_timeline.append({
                        "timestamp": f"00:0{i*10}:00",
                        "emotion": emotion,
                        "confidence": emotion_confidence,
                        "reliability": reliability,
                        "note": "í…ìŠ¤íŠ¸/ìŒì„± ë§¥ë½ê³¼ ë¶ˆì¼ì¹˜í•˜ì—¬ ê²€ì¦ í•„ìš”" if context_mismatch else None
                    })
            else:
                # confidenceê°€ ë‚®ìœ¼ë©´ ê°ì • ë¯¸ê²€ì¶œë¡œ í‘œì‹œ
                facial_timeline.append({
                    "timestamp": "00:00:00",
                    "emotion": "ê°ì • ë¯¸ê²€ì¶œ",
                    "confidence": confidence,
                    "reliability": "ë‚®ìŒ",
                    "note": f"í‘œì • ë¶„ì„ í™•ì‹¤ë„ {confidence}%ë¡œ ì‹ ì¤‘í•œ í•´ì„ì´ í•„ìš”í•©ë‹ˆë‹¤"
                })
        
        # ìŒì„± ì—ë„ˆì§€ íŒŒí˜• ë°ì´í„° (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        voice_waveform = None
        if audio_analysis.get("shout_detection"):
            shout_data = audio_analysis["shout_detection"]
            voice_waveform = {
                "average_energy": shout_data.get("average_energy", 0.5),
                "max_energy": shout_data.get("max_energy", 0.7),
                "detected_shout": shout_data.get("detected_shout", False),
                "energy_level": "ë†’ìŒ" if shout_data.get("average_energy", 0.5) > 0.6 else "ë³´í†µ"
            }
        
        # ì ìˆ˜ë³„ ì„¸ë¶€ ë¶„ì„
        score_breakdown = {}
        if emotion_evidence:
            score_breakdown = {
                "positive": {
                    "score": analysis.emotion_analysis.positive,
                    "factors": emotion_evidence.positive_factors[:3],
                    "explanation": f"ê¸ì • ì ìˆ˜ëŠ” {', '.join(emotion_evidence.positive_factors[:2])} ë“±ì˜ ìš”ì¸ìœ¼ë¡œ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤" if emotion_evidence.positive_factors else "ê¸ì •ì  í‘œí˜„ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
                },
                "depression": {
                    "score": analysis.emotion_analysis.depression,
                    "factors": emotion_evidence.depression_factors[:3],
                    "explanation": f"ìš°ìš¸ ì ìˆ˜ëŠ” {', '.join(emotion_evidence.depression_factors[:2])} ë“±ì˜ ìš”ì¸ìœ¼ë¡œ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤" if emotion_evidence.depression_factors else "ìš°ìš¸ ì§€í‘œê°€ ë‚®ìŠµë‹ˆë‹¤"
                },
                "anxiety": {
                    "score": analysis.emotion_analysis.anxiety,
                    "factors": emotion_evidence.anxiety_factors[:3],
                    "explanation": f"ë¶ˆì•ˆ ì ìˆ˜ëŠ” {', '.join(emotion_evidence.anxiety_factors[:2])} ë“±ì˜ ìš”ì¸ìœ¼ë¡œ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤" if emotion_evidence.anxiety_factors else "ë¶ˆì•ˆ ì§€í‘œê°€ ë‚®ìŠµë‹ˆë‹¤"
                }
            }
        else:
            # evidenceê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
            score_breakdown = {
                "positive": {
                    "score": analysis.emotion_analysis.positive,
                    "factors": [],
                    "explanation": "ëŒ€í™” ë‚´ìš© ë¶„ì„ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤"
                },
                "depression": {
                    "score": analysis.emotion_analysis.depression,
                    "factors": [],
                    "explanation": "ëŒ€í™” ë‚´ìš© ë¶„ì„ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤"
                }
            }
        
        # ë©€í‹°ëª¨ë‹¬ ì‹ ë¢°ë„ ê°€ì¤‘ í‰ê·  ê³„ì‚° (R4)
        text_confidence = 0.75  # í…ìŠ¤íŠ¸ ë¶„ì„ ê¸°ë³¸ ì‹ ë¢°ë„
        audio_confidence = 0.65 if audio_analysis.get("shout_detection") else 0.60
        face_confidence = image_analysis.get("confidence", 0) / 100.0 if image_analysis.get("analysis") else 0
        
        # ê°€ì¤‘ì¹˜: text 0.6, audio 0.25, face 0.15
        w_text, w_audio, w_face = 0.6, 0.25, 0.15
        overall_confidence = (w_text * text_confidence + w_audio * audio_confidence + w_face * face_confidence) * 100
        
        # ê³„ì‚° ë°©ë²• ì„¤ëª… + ë©€í‹°ëª¨ë‹¬ í™•ì‹¤ë„ í‘œì‹œ
        calculation_method = f"ê°ì • ì ìˆ˜ëŠ” ëŒ€í™” ë‚´ìš©(ê°€ì¤‘ì¹˜ 60%), ìŒì„± í†¤(ê°€ì¤‘ì¹˜ 25%), í‘œì • ë¶„ì„(ê°€ì¤‘ì¹˜ 15%)ì„ ì¢…í•©í•˜ì—¬ ê³„ì‚°í•©ë‹ˆë‹¤. "
        calculation_method += f"ì „ì²´ ì‹ ë¢°ë„: {overall_confidence:.1f}% (í…ìŠ¤íŠ¸ {text_confidence*100:.0f}%, ìŒì„± {audio_confidence*100:.0f}%, í‘œì • {face_confidence*100:.0f}%). "
        calculation_method += "ê° ì ìˆ˜ëŠ” 0-100 ë²”ìœ„ì´ë©°, ì—¬ëŸ¬ ìš”ì¸ì„ ê³ ë ¤í•˜ì—¬ ê²°ì •ë©ë‹ˆë‹¤."
        
        if emotion_evidence and emotion_evidence.facial_expression_notes:
            calculation_method += f" í‘œì • ë¶„ì„ ê²°ê³¼: '{emotion_evidence.facial_expression_notes[:50]}...'"
        
        return EvidenceVisualization(
            emotion_keywords=emotion_keywords,
            keyword_weights=keyword_weights,
            facial_expression_timeline=facial_timeline,
            voice_energy_waveform=voice_waveform,
            score_breakdown=score_breakdown,
            calculation_method=calculation_method
        )
    
    def _create_baseline_comparison(self, analysis: ComprehensiveAnalysisResult) -> Optional[Dict]:
        """Baseline ë¹„êµ ë°ì´í„° ìƒì„± (ëª…í™•í•œ í‘œí˜„ í•„ìˆ˜ í¬í•¨)"""
        baseline_comparisons = analysis.anomaly_analysis.baseline_comparisons
        
        # baseline_comparisonsê°€ ì—†ì–´ë„ ê¸°ë³¸ ì •ë³´ëŠ” ì œê³µ
        if not baseline_comparisons:
            # í˜„ì¬ ê°’ë§Œì´ë¼ë„ í‘œì‹œ
            return {
                "comparison_period": "ì§€ë‚œ 7ì¼ (ë°ì´í„° ë¶€ì¡±)",
                "current_values": {
                    "ê¸ì • ê°ì •": analysis.emotion_analysis.positive,
                    "ìš°ìš¸ ê°ì •": analysis.emotion_analysis.depression,
                    "ì™¸ë¡œì›€ ê°ì •": analysis.emotion_analysis.loneliness
                },
                "summary": "ê³¼ê±° ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ê°œì¸ í‰ê·  ë¹„êµëŠ” ì–´ë µìŠµë‹ˆë‹¤. í˜„ì¬ ìƒíƒœë§Œ í™•ì¸ë©ë‹ˆë‹¤.",
                "note": "ì¼ì£¼ì¼ ì´ìƒ ë°ì´í„°ê°€ ìŒ“ì´ë©´ ê°œì¸ í‰ê·  ëŒ€ë¹„ ë³€í™”ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            }
        
        # ëª¨ë“  ë³€í™” í¬í•¨ (ìœ ì˜ë¯¸í•œ ê²ƒê³¼ ì•„ë‹Œ ê²ƒ êµ¬ë¶„)
        all_changes = []
        significant_changes = []
        
        for comp in baseline_comparisons:
            change_data = {
                "metric": comp.metric,
                "current": comp.current_value,
                "baseline": comp.baseline_average,
                "difference": comp.difference,
                "difference_pct": comp.difference_percentage,
                "is_significant": comp.is_significant_change,
                "explanation": f"í‰ì†Œ í‰ê·  {comp.baseline_average:.1f}ì  â†’ ì˜¤ëŠ˜ {comp.current_value:.1f}ì  ({comp.difference:+.1f}ì , {comp.difference_percentage:+.1f}%)"
            }
            all_changes.append(change_data)
            if comp.is_significant_change:
                significant_changes.append(change_data)
        
        # ê°€ì¥ ì¤‘ìš”í•œ ë³€í™” ì¶”ì¶œ (ê¸ì • ê°ì • ë˜ëŠ” ìš°ìš¸ ê°ì •)
        mood_change = None
        for comp in baseline_comparisons:
            if comp.metric in ["ê¸ì • ê°ì •", "ìš°ìš¸ ê°ì •"]:
                mood_change = f"í‰ì†Œ í‰ê·  {comp.baseline_average:.0f}ì  â†’ ì˜¤ëŠ˜ {comp.current_value:.0f}ì  ({comp.difference:+.0f}ì  ê°ì†Œ)" if comp.difference < 0 else f"í‰ì†Œ í‰ê·  {comp.baseline_average:.0f}ì  â†’ ì˜¤ëŠ˜ {comp.current_value:.0f}ì  ({comp.difference:+.0f}ì  ì¦ê°€)"
                break
        
        summary = ""
        if significant_changes:
            summary = f"ì§€ë‚œ 7ì¼ í‰ê·  ëŒ€ë¹„ {len(significant_changes)}ê°œì˜ ìœ ì˜ë¯¸í•œ ë³€í™”ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. "
            if mood_change:
                summary += mood_change
        else:
            summary = "ì§€ë‚œ 7ì¼ í‰ê·  ëŒ€ë¹„ í° ë³€í™”ê°€ ì—†ìŠµë‹ˆë‹¤."
            if mood_change:
                summary += f" ({mood_change})"
        
        return {
            "comparison_period": "ì§€ë‚œ 7ì¼",
            "all_changes": all_changes,
            "significant_changes": significant_changes,
            "summary": summary,
            "mood_comparison": mood_change  # ê°€ì¥ ì¤‘ìš”í•œ ë¹„êµ ì •ë³´
        }
    
    def _create_medical_disclaimer(
        self, 
        analysis: ComprehensiveAnalysisResult, 
        action_plan: ActionPlan,
        key_concerns: List[KeyConcern]
    ) -> MedicalDisclaimer:
        """ì˜ë£Œ ì±…ì„ ë©´ì±… ì¡°í•­ ìƒì„± (R2: action_planê³¼ ì¼ì¹˜)"""
        # ê³ ì • ë©´ì±… ì¡°í•­
        disclaimer_text = (
            "ë³¸ ë¶„ì„ ê²°ê³¼ëŠ” ì°¸ê³ ìš© ì •ë³´ì´ë©°, ì˜ë£Œ ì§„ë‹¨ì´ ì•„ë‹™ë‹ˆë‹¤. "
            "ìš°ë ¤ê°€ ì§€ì†ë˜ë©´ ì˜ë£Œì§„ê³¼ ìƒë‹´í•˜ì„¸ìš”."
        )
        
        # action_planì˜ urgent_actionsì—ì„œ ê±´ê°• ê´€ë ¨ ì•¡ì…˜ í™•ì¸
        health_urgent_actions = []
        health_keywords = ["ì˜ì‚¬", "ë³‘ì›", "ìƒë‹´", "ì§„ë£Œ", "ì•½", "ì¦ìƒ", "í†µì¦", "ì‹ì‚¬", "ìŒì‹"]
        
        for action in action_plan.urgent_actions:
            if any(keyword in action.title or keyword in action.detail for keyword in health_keywords):
                health_urgent_actions.append(action)
        
        # key_concernsì—ì„œ ê±´ê°• ê´€ë ¨ urgent í™•ì¸
        health_urgent_concerns = [c for c in key_concerns if c.type == "ê±´ê°•" and c.severity == "urgent"]
        
        # suggested_action ìƒì„± (R2: action_planê³¼ ì¼ì¹˜)
        if health_urgent_actions or health_urgent_concerns:
            # urgent ì•¡ì…˜ì´ ìˆìœ¼ë©´ êµ¬ì²´ì ìœ¼ë¡œ í‘œì‹œ
            action_titles = [a.title for a in health_urgent_actions[:2]]
            if action_titles:
                suggested_action = f"ì´ë²ˆ ì£¼ ë‚´ ê°€ë²¼ìš´ ì§„ë£Œ ì˜ˆì•½ ê¶Œì¥ ({', '.join(action_titles[:2])})"
            else:
                concern_titles = [c.title for c in health_urgent_concerns[:2]]
                suggested_action = f"ì´ë²ˆ ì£¼ ë‚´ ê°€ë²¼ìš´ ì§„ë£Œ ì˜ˆì•½ ê¶Œì¥ ({', '.join(concern_titles[:2])})"
        else:
            # ì¼ë°˜ì ì¸ ê±´ê°• ê´€ë ¨ ê¶Œì¥ì‚¬í•­ë§Œ ìˆëŠ” ê²½ìš°
            has_health_mention = any(keyword in action.title for action in action_plan.this_week_actions for keyword in health_keywords)
            if has_health_mention:
                suggested_action = "ê±´ê°• ê´€ë ¨ ìš°ë ¤ì‚¬í•­ì´ ìˆìœ¼ë‹ˆ ì˜ë£Œì§„ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
            else:
                suggested_action = "í˜„ì¬ ê±´ê°• ê´€ë ¨ ê¶Œì¥ì‚¬í•­ì€ ì—†ìŠµë‹ˆë‹¤."
        
        return MedicalDisclaimer(
            disclaimer_text=disclaimer_text,
            is_recommendation_not_diagnosis=True,
            suggested_action=suggested_action
        )