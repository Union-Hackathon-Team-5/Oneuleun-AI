import asyncio
import contextlib
import json
import logging
import time
from typing import Any, Dict, List, Optional, Tuple
from datetime import datetime

from pydantic import ValidationError

from app.models.caregiver_models import (
    CaregiverFriendlyResponse, StatusOverview, TodaySummary, KeyConcern,
    ActionPlan, UrgentAction, DetailedAnalysis, TrendAnalysis, TrendChange,
    UIComponents, QuickStat, CTAButton, EmotionTimeline, VideoHighlight,
    RiskIndicator, AudioAnalysis, ConversationTopic, EvidenceVisualization,
    MedicalDisclaimer
)
from app.services.analysis_service import AnalysisService
from app.models.analysis_models import ComprehensiveAnalysisResult

logger = logging.getLogger(__name__)


class CaregiverService:
    """ë³´í˜¸ì ì¹œí™”ì  ë¶„ì„ ê²°ê³¼ ìƒì„± ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.analysis_service = AnalysisService()
        self._concern_type_aliases = {
            "ì‹ ì²´": "ê±´ê°•",
            "ì‹ ì²´ê±´ê°•": "ê±´ê°•",
            "ì˜ë£Œ": "ê±´ê°•",
            "í†µì¦": "ê±´ê°•",
            "health": "ê±´ê°•",
            "safety": "ì•ˆì „",
            "ì•ˆì „ìœ„í—˜": "ì•ˆì „",
            "ì •ì‹ ": "ì •ì„œ",
            "ì •ì‹ ê±´ê°•": "ì •ì„œ",
            "ì™¸ë¡œì›€": "ì •ì„œ",
            "ê³ ë¦½": "ì •ì„œ",
            "ìƒí™œí™˜ê²½": "ìƒí™œ",
            "ì¼ìƒ": "ìƒí™œ",
            "í™˜ê²½": "ìƒí™œ",
        }
    
    async def generate_caregiver_friendly_report(
        self,
        conversation: str,
        image_analysis: Dict,
        audio_analysis: Dict,
        session_id: str,
        user_id: str,
        historical_data: Optional[List[Dict]] = None
    ) -> CaregiverFriendlyResponse:
        """ë³´í˜¸ì ì¹œí™”ì  ë¦¬í¬íŠ¸ ìƒì„±"""
        start_time = time.time()
        
        # ê¸°ì¡´ ê¸°ìˆ ì  ë¶„ì„ ì‹¤í–‰ (historical_data í¬í•¨)
        print(f"[PERF] Starting comprehensive_analysis", flush=True)
        logger.info("[PERF] Starting comprehensive_analysis")
        comp_start = time.time()
        comprehensive_analysis, fact_snapshot = await self.analysis_service.analyze_video_letter_comprehensive(
            conversation=conversation,
            image_analysis=image_analysis,
            historical_data=historical_data
        )
        comp_time = time.time() - comp_start
        print(f"[PERF] comprehensive_analysis completed in {comp_time:.2f}s", flush=True)
        logger.info(f"[PERF] comprehensive_analysis completed in {comp_time:.2f}s")
        
        # ê°ì„±ì , ì•¡ì…˜ ì¤‘ì‹¬ ë¦¬í¬íŠ¸ë¡œ ë³€í™˜
        print(f"[PERF] Starting _transform_to_caregiver_format", flush=True)
        logger.info("[PERF] Starting _transform_to_caregiver_format")
        transform_start = time.time()
        result = await self._transform_to_caregiver_format(
            comprehensive_analysis=comprehensive_analysis,
            conversation=conversation,
            image_analysis=image_analysis,
            audio_analysis=audio_analysis,
            fact_snapshot=fact_snapshot,
            session_id=session_id,
            user_id=user_id
        )
        transform_time = time.time() - transform_start
        total_time = time.time() - start_time
        print(f"[PERF] _transform_to_caregiver_format completed in {transform_time:.2f}s", flush=True)
        print(f"[PERF] Total time: {total_time:.2f}s", flush=True)
        logger.info(f"[PERF] _transform_to_caregiver_format completed in {transform_time:.2f}s")
        logger.info(f"[PERF] Total time: {total_time:.2f}s")
        
        return result
    
    async def _transform_to_caregiver_format(
        self,
        comprehensive_analysis: ComprehensiveAnalysisResult,
        conversation: str,
        image_analysis: Dict,
        audio_analysis: Dict,
        fact_snapshot: Dict[str, Any],
        session_id: str,
        user_id: str
    ) -> CaregiverFriendlyResponse:
        """ê¸°ìˆ ì  ë¶„ì„ì„ ë³´í˜¸ì ì¹œí™”ì  í˜•íƒœë¡œ ë³€í™˜"""
        
        print(f"[PERF] Starting caregiver task race (bundle vs fallback)", flush=True)
        logger.info("[PERF] Starting caregiver task race (bundle vs fallback)")
        race_start = time.time()

        bundle_task = asyncio.create_task(
            self._generate_caregiver_bundle(
                conversation=conversation,
                comprehensive_analysis=comprehensive_analysis,
                image_analysis=image_analysis,
                fact_snapshot=fact_snapshot
            ),
            name="caregiver_bundle"
        )
        fallback_task = asyncio.create_task(
            self._run_legacy_caregiver_tasks(
                comprehensive_analysis=comprehensive_analysis,
                conversation=conversation,
                image_analysis=image_analysis
            ),
            name="caregiver_fallback"
        )

        emotional_insights: Dict[str, Any]
        action_plan: ActionPlan
        mother_voice: List[str]
        key_concerns: List[KeyConcern]

        done, pending = await asyncio.wait(
            {bundle_task, fallback_task},
            return_when=asyncio.FIRST_COMPLETED
        )

        bundle_result: Optional[Dict[str, Any]] = None
        fallback_result: Optional[Tuple[Dict[str, Any], ActionPlan, List[str], List[KeyConcern]]] = None

        if bundle_task in done:
            try:
                bundle_result = bundle_task.result()
            except asyncio.CancelledError:
                raise
            except Exception as exc:
                logger.error("Caregiver bundle execution error: %s", exc)
                bundle_result = None

        if fallback_task in done:
            try:
                fallback_result = fallback_task.result()
            except asyncio.CancelledError:
                raise
            except Exception as exc:
                logger.error("Fallback caregiver tasks error: %s", exc)
                fallback_result = None

        # Decide which result to use
        if bundle_result:
            # cancel fallback if still running
            if fallback_task not in done:
                fallback_task.cancel()
                with contextlib.suppress(asyncio.CancelledError):
                    await fallback_task
            emotional_insights, action_plan, mother_voice, key_concerns = self._parse_bundle_result(
                bundle_result,
                comprehensive_analysis
            )
            winner = "bundle"
        else:
            if fallback_result is None:
                # Wait for fallback to finish if bundle failed
                fallback_result = await fallback_task
            else:
                if bundle_task not in done:
                    bundle_task.cancel()
                    with contextlib.suppress(asyncio.CancelledError):
                        await bundle_task
            emotional_insights, action_plan, mother_voice, key_concerns = fallback_result
            winner = "fallback"

        race_time = time.time() - race_start
        print(f"[PERF] Caregiver task race winner: {winner} in {race_time:.2f}s", flush=True)
        logger.info("[PERF] Caregiver task race winner: %s in %.2fs", winner, race_time)
        
        # ë³‘ë ¬ LLM í˜¸ì¶œ ì´í›„ í›„ì²˜ë¦¬ ì‘ì—…ë“¤ ì‹œê°„ ì¸¡ì •
        post_process_start = time.time()
        
        # 1ìˆœìœ„: ìƒíƒœ ê°œìš” (key_concerns ìƒì„± í›„ì— ê²°ì •í•˜ì—¬ ì¼ê´€ì„± ë³´ì¥)
        status_overview = self._create_status_overview(comprehensive_analysis, key_concerns)
        
        # 2ìˆœìœ„: ì˜¤ëŠ˜ ìš”ì•½
        today_summary = self._create_today_summary(
            comprehensive_analysis, emotional_insights, mother_voice
        )
        
        # 3ìˆœìœ„: ì£¼ìš” ê±±ì •ê±°ë¦¬ (ì´ë¯¸ ìƒì„±ë¨)
        
        # 4ìˆœìœ„: í–‰ë™ ê³„íš (ì´ë¯¸ ìƒì„±ë¨)
        
        # 5ìˆœìœ„: ìƒì„¸ ë¶„ì„ (key_concernsì™€ ì¼ì¹˜ì‹œí‚´)
        detailed_analysis = self._create_detailed_analysis(
            comprehensive_analysis, conversation, audio_analysis, key_concerns
        )
        
        # Baseline ë¹„êµ ë°ì´í„° ìƒì„± (ì¶”ì„¸ ë¶„ì„ ì „ì— í•„ìš”)
        baseline_comparison = self._create_baseline_comparison(comprehensive_analysis)
        
        # 6ìˆœìœ„: ì¶”ì„¸ ë¶„ì„ (baseline ë¹„êµ ê¸°ë°˜ìœ¼ë¡œ í™œì„±í™”/ë¹„í™œì„±í™”)
        trend_analysis = self._create_trend_analysis(comprehensive_analysis, baseline_comparison)
        
        # UI ì»´í¬ë„ŒíŠ¸
        ui_components = self._create_ui_components(status_overview, comprehensive_analysis)
        
        # ê·¼ê±° ì‹œê°í™” ë°ì´í„° ìƒì„± (ë§¥ë½ ì¶©ëŒ ê°ì§€ í¬í•¨)
        evidence_viz = self._create_evidence_visualization(
            comprehensive_analysis, conversation, audio_analysis, image_analysis, key_concerns
        )
        
        # ì˜ë£Œ ì±…ì„ ë©´ì±… ì¡°í•­ ìƒì„± (action_planê³¼ ì¼ì¹˜ì‹œí‚´)
        medical_disclaimer = self._create_medical_disclaimer(comprehensive_analysis, action_plan, key_concerns)
        
        post_process_time = time.time() - post_process_start
        print(f"[PERF] Post-processing (data transformation) completed in {post_process_time:.2f}s", flush=True)
        
        return CaregiverFriendlyResponse(
            success=True,
            session_id=session_id,
            user_id=user_id,
            recorded_at=datetime.now().strftime("%Y-%m-%d %H:%M"),
            status_overview=status_overview,
            today_summary=today_summary,
            key_concerns=key_concerns,
            action_plan=action_plan,
            detailed_analysis=detailed_analysis,
            trend_analysis=trend_analysis,
            ui_components=ui_components,
            evidence_visualization=evidence_viz,
            baseline_comparison=baseline_comparison,
            medical_disclaimer=medical_disclaimer
        )
    
    async def _generate_emotional_insights(
        self, 
        conversation: str, 
        analysis: ComprehensiveAnalysisResult
    ) -> Dict:
        """ê°ì„±ì  ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        prompt = f"""
ë‹¤ìŒ ë…ê±°ë…¸ì¸ì˜ ëŒ€í™”ì—ì„œ ë³´í˜¸ìê°€ ì•Œì•„ì•¼ í•  ê°ì„±ì  í¬ì¸íŠ¸ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ëŒ€í™” ë‚´ìš©:
{conversation}

ë¶„ì„ ê²°ê³¼:
- ê°ì •: {analysis.emotion_analysis.overall_mood}
- ì£¼ìš” ìš°ë ¤: {analysis.comprehensive_summary.key_concerns}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "headline": "<ì–´ë¨¸ë‹ˆ ìƒíƒœë¥¼ í•œì¤„ë¡œ ìš”ì•½ (ê°ì„±ì ìœ¼ë¡œ)>",
    "mood_description": "<ê¸°ë¶„ ìƒíƒœë¥¼ ì¸ê°„ì ìœ¼ë¡œ ì„¤ëª…>",
    "energy_level": "<í™œë ¥ ìˆ˜ì¤€ ì„¤ëª…>",
    "pain_level": "<í†µì¦ ìˆ˜ì¤€ ì„¤ëª…>",
    "emotional_state": "<ì „ë°˜ì  ê°ì • ìƒíƒœ>"
}}

ì˜ˆì‹œ:
- "ì–´ë¨¸ë‹ˆê»˜ì„œ ë§ì´ í˜ë“¤ì–´í•˜ì‹­ë‹ˆë‹¤"
- "í‰ì†Œë³´ë‹¤ ë§ì´ ì§€ì³ ë³´ì´ì„¸ìš”"
- "ì™¸ë¡œì›€ì„ ë§ì´ ëŠë¼ê³  ê³„ì‹  ê²ƒ ê°™ì•„ìš”"
"""
        
        try:
            task_start = time.time()
            response = await self.analysis_service._call_openai(prompt, max_tokens=500, task_name="_generate_emotional_insights")
            task_time = time.time() - task_start
            print(f"[PERF] _generate_emotional_insights API call: {task_time:.2f}s", flush=True)
            logger.debug(f"[PERF] _generate_emotional_insights API call: {task_time:.2f}s")
            return json.loads(response)
        except Exception as exc:
            logger.error("Failed to generate emotional insights: %s", exc)
            return {
                "headline": "ì–´ë¨¸ë‹ˆ ìƒíƒœë¥¼ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤",
                "mood_description": "í‰ì†Œë³´ë‹¤ ê¸°ë¶„ì´ ì¢‹ì§€ ì•Šìœ¼ì‹  ê²ƒ ê°™ì•„ìš”",
                "energy_level": "í™œë ¥ì´ ë¶€ì¡±í•´ ë³´ì…ë‹ˆë‹¤",
                "pain_level": "ëª¸ì´ ë¶ˆí¸í•˜ì‹  ê²ƒ ê°™ì•„ìš”",
                "emotional_state": "ê´€ì‹¬ê³¼ ëŒë´„ì´ í•„ìš”í•œ ìƒíƒœì…ë‹ˆë‹¤"
            }

    def _build_action_plan_from_dict(self, data: Dict) -> ActionPlan:
        """LLMì´ ìƒì„±í•œ ë”•ì…”ë„ˆë¦¬ë¥¼ ActionPlan ëª¨ë¸ë¡œ ë³€í™˜ (ìš°ì„ ìˆœìœ„ ì •ê·œí™”, ì¤‘ë³µ ì œê±° í¬í•¨)"""
        valid_priorities = ["ìµœìš°ì„ ", "ê¸´ê¸‰", "ì¤‘ìš”"]

        def normalize_action(action: Dict) -> Dict:
            if "priority" in action:
                priority = action["priority"]
                if priority not in valid_priorities:
                    if priority in ["ë³´í†µ", "ë‚®ìŒ", "normal", "low"]:
                        action["priority"] = "ì¤‘ìš”"
                    elif priority in ["ë†’ìŒ", "high", "urgent"]:
                        action["priority"] = "ê¸´ê¸‰"
                    else:
                        action["priority"] = "ì¤‘ìš”"
            else:
                action["priority"] = "ì¤‘ìš”"
            return action

        def deduplicate(actions: List[Dict]) -> List[Dict]:
            seen_titles = set()
            unique_actions = []
            for action in actions:
                title = action.get("title", "").strip()
                if not title or title in seen_titles:
                    continue
                seen_titles.add(title)
                unique_actions.append(action)
            return unique_actions

        urgent_actions_raw = deduplicate(data.get("urgent_actions", []))
        this_week_actions_raw = deduplicate(data.get("this_week_actions", []))
        long_term_actions_raw = deduplicate(data.get("long_term_actions", []))

        urgent_actions = [UrgentAction.model_validate(normalize_action(action)) for action in urgent_actions_raw]
        this_week_actions = [UrgentAction.model_validate(normalize_action(action)) for action in this_week_actions_raw]
        long_term_actions = [UrgentAction.model_validate(normalize_action(action)) for action in long_term_actions_raw]

        return ActionPlan(
            urgent_actions=urgent_actions,
            this_week_actions=this_week_actions,
            long_term_actions=long_term_actions
        )

    def _normalize_concern_entry(self, concern: Dict[str, Any], idx: int) -> Dict[str, Any]:
        concern = dict(concern)
        concern_type = str(concern.get("type", "")).strip()
        normalized = self._concern_type_aliases.get(concern_type, concern_type)
        if normalized not in {"ê±´ê°•", "ì•ˆì „", "ì •ì„œ", "ìƒí™œ"}:
            logger.warning("Unknown concern type '%s' at index %s, defaulting to 'ì •ì„œ'", concern_type, idx)
            normalized = "ì •ì„œ"
        concern["type"] = normalized
        return concern

    async def _generate_actionable_plan(
        self, 
        analysis: ComprehensiveAnalysisResult, 
        conversation: str
    ) -> ActionPlan:
        """ì‹¤í–‰ ê°€ëŠ¥í•œ í–‰ë™ ê³„íš ìƒì„± (ê³¼ë„í•œ ê²½ê³  ë°©ì§€)"""
        
        # baseline ë¹„êµ ì •ë³´ ì¶”ê°€
        baseline_context = ""
        if analysis.anomaly_analysis.baseline_comparisons:
            significant = [c for c in analysis.anomaly_analysis.baseline_comparisons if c.is_significant_change]
            if significant:
                baseline_context = f"\nê°œì¸ baseline ë¹„êµ: {len(significant)}ê°œì˜ ìœ ì˜ë¯¸í•œ ë³€í™” ê°ì§€"
        
        # í”„ë¡¬í”„íŠ¸ ìµœì í™”: ë” ê°„ê²°í•˜ê²Œ
        key_concerns_str = ", ".join(analysis.comprehensive_summary.key_concerns[:2]) if analysis.comprehensive_summary.key_concerns else "ì—†ìŒ"
        recommended_str = ", ".join(analysis.comprehensive_summary.recommended_actions[:2]) if analysis.comprehensive_summary.recommended_actions else "ì—†ìŒ"
        
        prompt = f"""í–‰ë™ ê³„íš ìƒì„± (ê°„ê²°, í•„ìˆ˜ë§Œ):

ìœ„í—˜ë„: {analysis.comprehensive_summary.priority_level}
ìš°ë ¤: {key_concerns_str}
ì¡°ì¹˜: {recommended_str}

JSON ì‘ë‹µ (ìµœì†Œí™”):
{{
    "urgent_actions": [{{"action_id": 1, "priority": "ìµœìš°ì„ ", "icon": "ğŸ“", "title": "ì œëª©", "reason": "ì´ìœ ", "detail": "ë§ì”€", "deadline": "ì˜¤ëŠ˜", "estimated_time": "10ë¶„", "suggested_topics": ["ì˜ˆì‹œ1", "ì˜ˆì‹œ2"]}}],
    "this_week_actions": [{{"action_id": 2, "priority": "ì¤‘ìš”", "icon": "ğŸ“…", "title": "ì œëª©", "reason": "ì´ìœ ", "detail": "ë§ì”€", "deadline": "ì´ë²ˆì£¼", "estimated_time": "30ë¶„", "suggested_topics": ["ì˜ˆì‹œ"]}}],
    "long_term_actions": []
}}

ê·œì¹™:
- urgent ìµœëŒ€ 2ê°œ, this_week ìµœëŒ€ 3ê°œ, long_term ìµœëŒ€ 2ê°œ.
- ì—°ë½ ë°©ë²•ì€ ë°˜ë³µí•˜ì§€ ë§ê³  ë‹¤ì–‘í•˜ê²Œ ì œì‹œ (ì˜ˆ: ì „í™”, ìŒì„± ë©”ì‹œì§€, ì˜ìƒ í†µí™” ì˜ˆì•½, ë°©ë¬¸ ì¼ì •, ë³µì§€ì„¼í„° í”„ë¡œê·¸ë¨ ë“±).
- ê° ì•¡ì…˜ì€ êµ¬ì²´ì  ì´ìœ ì™€ ì‹¤í–‰ ë°©ë²•ì„ ì œê³µí•˜ê³ , 1-2ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±.
- priorityëŠ” "ìµœìš°ì„ ", "ê¸´ê¸‰", "ì¤‘ìš”"ë§Œ.
"""
        
        try:
            task_start = time.time()
            # max_tokensë¥¼ 500ìœ¼ë¡œ ë” ì¤„ì„ (ê° ì•¡ì…˜ í•„ë“œë¥¼ ë” ê°„ê²°í•˜ê²Œ ë§Œë“¤ì—ˆìœ¼ë¯€ë¡œ)
            response = await self.analysis_service._call_openai(prompt, max_tokens=500, task_name="_generate_actionable_plan")
            task_time = time.time() - task_start
            print(f"[PERF] _generate_actionable_plan API call: {task_time:.2f}s", flush=True)
            logger.debug(f"[PERF] _generate_actionable_plan API call: {task_time:.2f}s")
            data = json.loads(response)
            return self._build_action_plan_from_dict(data)
        except Exception as exc:
            logger.error("Failed to generate action plan: %s", exc)
            return self._create_default_action_plan(analysis)
    
    async def _extract_mother_voice(self, conversation: str) -> List[str]:
        """ì–´ë¨¸ë‹ˆ ëª©ì†Œë¦¬ ì§ì ‘ ì¸ìš© ì¶”ì¶œ"""
        prompt = f"""
ë‹¤ìŒ ëŒ€í™”ì—ì„œ ë…ê±°ë…¸ì¸(ì–´ë¨¸ë‹ˆ)ì´ ì§ì ‘ í•˜ì‹  ë§ì”€ ì¤‘ì—ì„œ ë³´í˜¸ìê°€ ë“¤ìœ¼ë©´ ë§ˆìŒì´ ì•„í”„ê±°ë‚˜ ê±±ì •ì´ ë  ë§Œí•œ ë¶€ë¶„ì„ ì°¾ì•„ì„œ ì§ì ‘ ì¸ìš©í•´ì£¼ì„¸ìš”.

ëŒ€í™” ë‚´ìš©:
{conversation}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "mother_voice": [
        "ğŸ’¬ \\"ì‹¤ì œ ì–´ë¨¸ë‹ˆê°€ í•˜ì‹  ë§ì”€1\\"",
        "ğŸ’¬ \\"ì‹¤ì œ ì–´ë¨¸ë‹ˆê°€ í•˜ì‹  ë§ì”€2\\"",
        "ğŸ’¬ \\"ì‹¤ì œ ì–´ë¨¸ë‹ˆê°€ í•˜ì‹  ë§ì”€3\\"",
        "ğŸ’¬ \\"ì‹¤ì œ ì–´ë¨¸ë‹ˆê°€ í•˜ì‹  ë§ì”€4\\""
    ]
}}

ì˜ˆì‹œ:
- "ğŸ’¬ \"ìš”ì¦˜ì€ ìê¾¸ í”¼ê³¤í•´ì„œ ë­˜ í•´ë„ ê¸ˆë°© ì§€ì¹˜ëŠ” ëŠë‚Œì´ì—ìš”\""
- "ğŸ’¬ \"ë©°ì¹ ì§¸ ë°¥ë§›ì´ ì—†ê³  ì”¹ëŠ” ê²ƒë„ ì¢€ í˜ë“¤ì–´ì„œìš”\""
- "ğŸ’¬ \"ê³„ì† ì§‘ì—ë§Œ ìˆë‹¤ ë³´ë‹ˆê¹Œ ì‚¬ëŒ ëª©ì†Œë¦¬ê°€ ê·¸ë¦½ë„¤ìš”\""
"""
        
        try:
            task_start = time.time()
            response = await self.analysis_service._call_openai(prompt, max_tokens=400, task_name="_extract_mother_voice")
            task_time = time.time() - task_start
            print(f"[PERF] _extract_mother_voice API call: {task_time:.2f}s", flush=True)
            logger.debug(f"[PERF] _extract_mother_voice API call: {task_time:.2f}s")
            data = json.loads(response)
            return data.get("mother_voice", [])
        except Exception as exc:
            logger.error("Failed to extract mother voice: %s", exc)
            return [
                "ğŸ’¬ \"ìš”ì¦˜ ì»¨ë””ì…˜ì´ ë³„ë¡œ ì¢‹ì§€ ì•Šì•„ìš”\"",
                "ğŸ’¬ \"í˜¼ì ìˆëŠ” ì‹œê°„ì´ ë§ì•„ì„œ ì™¸ë¡œì›Œìš”\"",
                "ğŸ’¬ \"ëª¸ì´ ì˜ˆì „ ê°™ì§€ ì•Šì•„ì„œ ê±±ì •ì´ì—ìš”\""
            ]

    async def _generate_caregiver_bundle(
        self,
        conversation: str,
        comprehensive_analysis: ComprehensiveAnalysisResult,
        image_analysis: Dict,
        fact_snapshot: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """ê°ì„± ì¸ì‚¬ì´íŠ¸, í–‰ë™ ê³„íš, ì£¼ìš” ê±±ì •ê±°ë¦¬, ì–´ë¨¸ë‹ˆ ëª©ì†Œë¦¬ë¥¼ í•œ ë²ˆì˜ í˜¸ì¶œë¡œ ìƒì„±"""
        summary = comprehensive_analysis.comprehensive_summary
        emotion = comprehensive_analysis.emotion_analysis
        risk = comprehensive_analysis.risk_analysis
        anomaly = comprehensive_analysis.anomaly_analysis

        image_concerns = []
        if image_analysis.get("analysis"):
            image_concerns = image_analysis["analysis"].get("concerns", [])
        image_concern_text = ", ".join(image_concerns) if image_concerns else "ì—†ìŒ"

        trend_label = anomaly.pattern_type if anomaly.pattern_type != "ì—†ìŒ" else anomaly.trend_analysis

        fact_json = json.dumps(fact_snapshot, ensure_ascii=False)

        convo_lines = [line.strip() for line in conversation.splitlines() if line.strip()]
        trimmed_conversation = "\n".join(convo_lines[-20:])  # ìµœì‹  ë°œì–¸ ìœ„ì£¼ 20ì¤„

        prompt = f"""
ë‹¹ì‹ ì€ ë…ê±°ë…¸ì¸ ì¼€ì–´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³´í˜¸ììš© ë³´ê³ ì„œ ìš”ì†Œë¥¼ í•œ ë²ˆì— ìƒì„±í•˜ì„¸ìš”.

Facts ìŠ¤ëƒ…ìƒ·:
{fact_json}

ê°ì • ì ìˆ˜: ê¸ì • {emotion.positive}/100, ë¶ˆì•ˆ {emotion.anxiety}/100, ìš°ìš¸ {emotion.depression}/100, ì™¸ë¡œì›€ {emotion.loneliness}/100
ì „ë°˜ ê¸°ë¶„: {emotion.overall_mood}
ìš°ì„ ìˆœìœ„: {summary.priority_level}, ìƒíƒœ ìš”ì•½: {summary.main_summary}
ìœ„í—˜ë„: {risk.risk_level}, ì¦‰ì‹œ ìš°ë ¤: {', '.join(risk.immediate_concerns) or 'ì—†ìŒ'}
ì´ë¯¸ì§€ ìš°ë ¤: {image_concern_text}
ì¶”ì„¸/íŒ¨í„´: {trend_label}

ìµœê·¼ ëŒ€í™” ë°œì·Œ:
{trimmed_conversation}

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
  "emotional_insights": {{
    "headline": "<ê°ì„± ìš”ì•½ ì œëª©>",
    "mood_description": "<ê¸°ë¶„ ì„¤ëª…>",
    "energy_level": "<í™œë ¥ ì„¤ëª…>",
    "pain_level": "<ì‹ ì²´ ë¶ˆí¸ ì„¤ëª…>",
    "emotional_state": "<ì „ë°˜ ê°ì • ìƒíƒœ>"
  }},
  "action_plan": {{
    "urgent_actions": [
      {{
        "action_id": 1,
        "priority": "ìµœìš°ì„ ",
        "icon": "ğŸ“",
        "title": "ì œëª©",
        "reason": "ì´ìœ ",
        "detail": "ì‹¤í–‰ ë°©ë²•",
        "deadline": "ì˜¤ëŠ˜",
        "estimated_time": "10ë¶„",
        "suggested_topics": ["ì˜ˆì‹œ"]
      }}
    ],
    "this_week_actions": [],
    "long_term_actions": []
  }},
  "mother_voice": ["ğŸ’¬ \"ì‹¤ì œ ì¸ìš©\""],
  "key_concerns": [
    {{
      "concern_id": 1,
      "type": "ê±´ê°•|ì•ˆì „|ì •ì„œ|ìƒí™œ",
      "icon": "ğŸ¥",
      "severity": "urgent|caution|normal",
      "title": "ê±±ì • ìš”ì•½",
      "description": "ê°„ê²°í•œ ì„¤ëª…",
      "detected_from": ["ëŒ€í™”", "í‘œì •"],
      "urgency_reason": "ì´ í•­ëª©ì´ ì¤‘ìš”í•œ ì´ìœ "
    }}
  ]
}}

ê·œì¹™:
- action_plan í•­ëª©ì€ ìµœëŒ€ 6ê°œ(ê¸´ê¸‰ 2, ì´ë²ˆ ì£¼ 3, ì¥ê¸° 1) ì´ë‚´ì´ë©°, ì—°ë½ ë°©ë²•ì„ ì¤‘ë³µí•˜ì§€ ë§ê³  ë‹¤ì–‘í•˜ê²Œ ì œì•ˆí•˜ì„¸ìš” (ì „í™”, ìŒì„± ë©”ì‹œì§€, ì˜ìƒ í†µí™”, ë°©ë¬¸ ì˜ˆì•½, ë³µì§€ì„¼í„° í”„ë¡œê·¸ë¨ ë“±).
- ìš°ìš¸/ì ˆë§ ì§•í›„ê°€ ê°•í•˜ë©´ concernsì— 'ìš°ìš¸ì¦ ìš°ë ¤', 'ìì‚´ ìœ„í—˜ ì˜ì‹¬' ë“±ì„ ëª…ì‹œí•˜ê³ , action_planì—ë„ ì´ì— ëŒ€í•œ êµ¬ì²´ ì¡°ì¹˜ë¥¼ í¬í•¨í•˜ì„¸ìš”.
- mother_voiceì—ëŠ” ì‹¤ì œ ëŒ€í™” ì¸ìš©ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ facts.notable_quotesì—ì„œ ê³¨ë¼ì£¼ì„¸ìš”.
- key_concernsëŠ” ê°€ì¥ ì¤‘ìš”í•œ 3ê°œê¹Œì§€, severityì™€ urgency_reasonì„ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
"""

        bundle_schema = {
            "name": "caregiver_bundle",
            "schema": {
                "type": "object",
                "properties": {
                    "emotional_insights": {
                        "type": "object",
                        "properties": {
                            "headline": {"type": "string"},
                            "mood_description": {"type": "string"},
                            "energy_level": {"type": "string"},
                            "pain_level": {"type": "string"},
                            "emotional_state": {"type": "string"},
                        },
                        "required": ["headline", "mood_description", "energy_level", "pain_level", "emotional_state"],
                        "additionalProperties": False,
                    },
                    "action_plan": {
                        "type": "object",
                        "properties": {
                            "urgent_actions": {
                                "type": "array",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "action_id": {"type": "integer"},
                                        "priority": {"type": "string", "enum": ["ìµœìš°ì„ ", "ê¸´ê¸‰", "ì¤‘ìš”"]},
                                        "icon": {"type": "string"},
                                        "title": {"type": "string"},
                                        "reason": {"type": "string"},
                                        "detail": {"type": "string"},
                                        "deadline": {"type": "string"},
                                        "estimated_time": {"type": "string"},
                                        "suggested_topics": {
                                            "type": "array",
                                            "items": {"type": "string"},
                                            "maxItems": 4
                                        }
                                    },
                                    "required": ["action_id", "priority", "icon", "title", "reason", "detail", "deadline", "estimated_time"],
                                    "additionalProperties": False
                                },
                                "maxItems": 2
                            },
                            "this_week_actions": {
                                "type": "array",
                                "items": {"$ref": "#/$defs/action_item"},
                                "maxItems": 3
                            },
                            "long_term_actions": {
                                "type": "array",
                                "items": {"$ref": "#/$defs/action_item"},
                                "maxItems": 2
                            }
                        },
                        "required": ["urgent_actions", "this_week_actions", "long_term_actions"],
                        "additionalProperties": False
                    },
                    "mother_voice": {
                        "type": "array",
                        "items": {"type": "string"},
                        "maxItems": 4
                    },
                    "key_concerns": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "concern_id": {"type": "integer"},
                                "type": {"type": "string", "enum": ["ê±´ê°•", "ì•ˆì „", "ì •ì„œ", "ìƒí™œ"]},
                                "icon": {"type": "string"},
                                "severity": {"type": "string", "enum": ["urgent", "caution", "normal"]},
                                "title": {"type": "string"},
                                "description": {"type": "string"},
                                "detected_from": {
                                    "type": "array",
                                    "items": {"type": "string"},
                                    "maxItems": 3
                                },
                                "urgency_reason": {"type": "string"}
                            },
                            "required": ["concern_id", "type", "icon", "severity", "title", "description", "detected_from", "urgency_reason"],
                            "additionalProperties": False
                        },
                        "maxItems": 3
                    }
                },
                "required": ["emotional_insights", "action_plan", "mother_voice", "key_concerns"],
                "additionalProperties": False,
                "$defs": {
                    "action_item": {
                        "type": "object",
                        "properties": {
                            "action_id": {"type": "integer"},
                            "priority": {"type": "string", "enum": ["ìµœìš°ì„ ", "ê¸´ê¸‰", "ì¤‘ìš”"]},
                            "icon": {"type": "string"},
                            "title": {"type": "string"},
                            "reason": {"type": "string"},
                            "detail": {"type": "string"},
                            "deadline": {"type": "string"},
                            "estimated_time": {"type": "string"},
                            "suggested_topics": {
                                "type": "array",
                                "items": {"type": "string"},
                                "maxItems": 4
                            }
                        },
                        "required": ["action_id", "priority", "icon", "title", "reason", "detail", "deadline", "estimated_time"],
                        "additionalProperties": False
                    }
                }
            }
        }

        try:
            response = await self.analysis_service._call_openai(
                prompt,
                max_tokens=700,
                task_name="_generate_caregiver_bundle",
                timeout_seconds=8.0,
                temperature=0.25,
                response_format={"type": "json_schema", "json_schema": bundle_schema}
            )
            return json.loads(response)
        except Exception as exc:
            logger.error("Failed to generate caregiver bundle: %s", exc)
            return None
    
    async def _run_legacy_caregiver_tasks(
        self,
        comprehensive_analysis: ComprehensiveAnalysisResult,
        conversation: str,
        image_analysis: Dict
    ) -> Tuple[Dict[str, Any], ActionPlan, List[str], List[KeyConcern]]:
        """ê¸°ì¡´ 4ë¶„í•  LLM í˜¸ì¶œì„ ë³‘ë ¬ë¡œ ì‹¤í–‰"""
        default_emotional = {
            "headline": "ì–´ë¨¸ë‹ˆ ìƒíƒœë¥¼ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤",
            "mood_description": "í‰ì†Œë³´ë‹¤ ê¸°ë¶„ì´ ì¢‹ì§€ ì•Šìœ¼ì‹  ê²ƒ ê°™ì•„ìš”",
            "energy_level": "í™œë ¥ì´ ë¶€ì¡±í•´ ë³´ì…ë‹ˆë‹¤",
            "pain_level": "ëª¸ì´ ë¶ˆí¸í•˜ì‹  ê²ƒ ê°™ì•„ìš”",
            "emotional_state": "ê´€ì‹¬ê³¼ ëŒë´„ì´ í•„ìš”í•œ ìƒíƒœì…ë‹ˆë‹¤"
        }
        default_action_plan = self._create_default_action_plan(comprehensive_analysis)
        default_mother_voice = [
            "ğŸ’¬ \"ìš”ì¦˜ ì»¨ë””ì…˜ì´ ë³„ë¡œ ì¢‹ì§€ ì•Šì•„ìš”\"",
            "ğŸ’¬ \"í˜¼ì ìˆëŠ” ì‹œê°„ì´ ë§ì•„ì„œ ì™¸ë¡œì›Œìš”\"",
            "ğŸ’¬ \"ëª¸ì´ ì˜ˆì „ ê°™ì§€ ì•Šì•„ì„œ ê±±ì •ì´ì—ìš”\""
        ]
        default_concerns = self._create_default_concerns(comprehensive_analysis)

        async def safe_call(coro, timeout: float, label: str, default_value):
            try:
                return await asyncio.wait_for(coro, timeout)
            except asyncio.CancelledError:
                raise
            except Exception as exc:
                logger.error("%s failed/timeout: %s", label, exc)
                return default_value

        tasks = [
            asyncio.create_task(
                safe_call(
                    self._generate_emotional_insights(conversation, comprehensive_analysis),
                    10.0,
                    "Emotional insights",
                    default_emotional
                ),
                name="legacy_emotional_insights"
            ),
            asyncio.create_task(
                safe_call(
                    self._generate_actionable_plan(comprehensive_analysis, conversation),
                    10.0,
                    "Action plan",
                    default_action_plan
                ),
                name="legacy_action_plan"
            ),
            asyncio.create_task(
                safe_call(
                    self._extract_mother_voice(conversation),
                    10.0,
                    "Mother voice",
                    default_mother_voice
                ),
                name="legacy_mother_voice"
            ),
            asyncio.create_task(
                safe_call(
                    self._identify_key_concerns(comprehensive_analysis, conversation, image_analysis),
                    10.0,
                    "Key concerns",
                    default_concerns
                ),
                name="legacy_key_concerns"
            ),
        ]

        results = await asyncio.gather(*tasks)
        emotional_insights = results[0]
        action_plan = results[1]
        mother_voice = results[2]
        key_concerns = results[3]
        return emotional_insights, action_plan, mother_voice, key_concerns

    def _parse_bundle_result(
        self,
        bundle: Dict[str, Any],
        comprehensive_analysis: ComprehensiveAnalysisResult
    ) -> Tuple[Dict[str, Any], ActionPlan, List[str], List[KeyConcern]]:
        emotional_insights = bundle.get("emotional_insights") or {}
        if not emotional_insights:
            emotional_insights = {
                "headline": "ì–´ë¨¸ë‹ˆ ìƒíƒœë¥¼ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤",
                "mood_description": "í‰ì†Œë³´ë‹¤ ê¸°ë¶„ì´ ì¢‹ì§€ ì•Šìœ¼ì‹  ê²ƒ ê°™ì•„ìš”",
                "energy_level": "í™œë ¥ì´ ë¶€ì¡±í•´ ë³´ì…ë‹ˆë‹¤",
                "pain_level": "ëª¸ì´ ë¶ˆí¸í•˜ì‹  ê²ƒ ê°™ì•„ìš”",
                "emotional_state": "ê´€ì‹¬ê³¼ ëŒë´„ì´ í•„ìš”í•œ ìƒíƒœì…ë‹ˆë‹¤"
            }

        action_plan_data = bundle.get("action_plan") or {}
        try:
            action_plan = self._build_action_plan_from_dict(action_plan_data)
        except Exception as exc:
            logger.error("Failed to parse bundled action plan: %s", exc)
            action_plan = self._create_default_action_plan(comprehensive_analysis)

        mother_voice = bundle.get("mother_voice") or []
        if not isinstance(mother_voice, list):
            mother_voice = []
        mother_voice = [str(item).strip() for item in mother_voice if str(item).strip()]
        if not mother_voice:
            mother_voice = [
                "ğŸ’¬ \"ìš”ì¦˜ ì»¨ë””ì…˜ì´ ë³„ë¡œ ì¢‹ì§€ ì•Šì•„ìš”\"",
                "ğŸ’¬ \"í˜¼ì ìˆëŠ” ì‹œê°„ì´ ë§ì•„ì„œ ì™¸ë¡œì›Œìš”\"",
                "ğŸ’¬ \"ëª¸ì´ ì˜ˆì „ ê°™ì§€ ì•Šì•„ì„œ ê±±ì •ì´ì—ìš”\""
            ]

        key_concerns_data = bundle.get("key_concerns") or []
        parsed_concerns: List[KeyConcern] = []
        for idx, concern in enumerate(key_concerns_data, start=1):
            try:
                normalized = self._normalize_concern_entry(concern, idx)
                parsed_concerns.append(KeyConcern.model_validate(normalized))
            except ValidationError as exc:
                logger.error("Invalid concern item at %s: %s", idx, exc)
        key_concerns = parsed_concerns or self._create_default_concerns(comprehensive_analysis)

        return emotional_insights, action_plan, mother_voice, key_concerns
    
    async def _identify_key_concerns(
        self, 
        analysis: ComprehensiveAnalysisResult, 
        conversation: str, 
        image_analysis: Dict
    ) -> List[KeyConcern]:
        """ì£¼ìš” ê±±ì •ê±°ë¦¬ ì‹ë³„ (ê°€ì¡± ì¼€ì–´ ì¡°ì–¸ í†¤)"""
        # ìœ„í—˜ ë¶„ì„ ì •ë³´ ê°„ì†Œí™”
        risk_level = analysis.risk_analysis.risk_level
        risk_keywords = ", ".join(analysis.risk_analysis.detected_keywords[:5])
        image_concerns = ", ".join(image_analysis.get('analysis', {}).get('concerns', [])[:3])
        
        prompt = f"""ì£¼ìš” ê±±ì •ê±°ë¦¬ ì‹ë³„ (ìµœëŒ€ 5ê°œ):

ëŒ€í™” ìš”ì•½: {conversation[:300]}...
ìœ„í—˜ë„: {risk_level}
ìœ„í—˜ í‚¤ì›Œë“œ: {risk_keywords}
ì´ë¯¸ì§€ ìš°ë ¤: {image_concerns or "ì—†ìŒ"}

JSON í˜•ì‹ (ê°„ê²°í•˜ê²Œ):
{{
    "concerns": [
        {{
            "concern_id": 1,
            "type": "ê±´ê°•|ì•ˆì „|ì •ì„œ|ìƒí™œ",
            "icon": "ğŸ¥",
            "severity": "urgent|caution|normal",
            "title": "êµ¬ì²´ì  ë¬¸ì œ",
            "description": "ê°€ì¡± ì¼€ì–´ ì¡°ì–¸ í†¤ìœ¼ë¡œ ê°„ë‹¨íˆ ì„¤ëª…",
            "detected_from": ["ëŒ€í™”", "í‘œì •"],
            "urgency_reason": "ì™œ ì¤‘ìš”í•œì§€"
        }}
    ]
}}

ì£¼ì˜: "ì˜ë£Œì§„ ìƒë‹´ ê¶Œì¥" í‘œí˜„ ì‚¬ìš©. "ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”" ê°™ì€ í‘œí˜„ í”¼í•˜ê¸°.
"""
        
        try:
            task_start = time.time()
            # max_tokensë¥¼ 600ìœ¼ë¡œ ì¦ê°€ (JSON íŒŒì‹± ì—ëŸ¬ ë°©ì§€, concernsëŠ” ë³´í†µ 3-5ê°œ)
            response = await self.analysis_service._call_openai(prompt, max_tokens=600, task_name="_identify_key_concerns")
            task_time = time.time() - task_start
            print(f"[PERF] _identify_key_concerns API call: {task_time:.2f}s", flush=True)
            logger.debug(f"[PERF] _identify_key_concerns API call: {task_time:.2f}s")
            
            # JSON íŒŒì‹± ì „ì— ì‘ë‹µ í™•ì¸ ë° ì •ë¦¬
            response = response.strip()
            # JSON íŒŒì‹± ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•œ ì²˜ë¦¬
            if not response.startswith('{'):
                # JSON ì‹œì‘ ë¶€ë¶„ ì°¾ê¸°
                start_idx = response.find('{')
                if start_idx > 0:
                    response = response[start_idx:]
            # JSON ë ë¶€ë¶„ ì •ë¦¬
            if not response.endswith('}'):
                # ë§ˆì§€ë§‰ ë‹«ëŠ” ì¤‘ê´„í˜¸ ì°¾ê¸°
                last_idx = response.rfind('}')
                if last_idx > 0:
                    response = response[:last_idx+1]
            
            data = json.loads(response)
            # Pydantic model_validateë¡œ ìµœì í™”
            return [KeyConcern.model_validate(concern) for concern in data.get("concerns", [])]
        except Exception as exc:
            logger.error("Failed to identify key concerns: %s", exc)
            return self._create_default_concerns(analysis)
    
    def _create_status_overview(self, analysis: ComprehensiveAnalysisResult, key_concerns: List[KeyConcern]) -> StatusOverview:
        """ìƒíƒœ ê°œìš” ìƒì„± (Alert level ì¼ê´€ì„± ë³´ì¥: ìµœê³  ìœ„í—˜ë„ ê¸°ì¤€)"""
        # ìµœê³  ìœ„í—˜ë„ ê¸°ì¤€ìœ¼ë¡œ ë‹¨ì¼í™” (key_concernsì˜ ìµœê³  severity ìš°ì„ )
        max_concern_severity = "normal"
        if key_concerns:
            # key_concernsì—ì„œ ìµœê³  severity ì°¾ê¸°
            severity_map = {"urgent": 3, "caution": 2, "normal": 1}
            max_severity_value = max(severity_map.get(concern.severity, 1) for concern in key_concerns)
            max_concern_severity = [k for k, v in severity_map.items() if v == max_severity_value][0]
        
        # baseline ë¹„êµë¥¼ ê³ ë ¤í•˜ì—¬ ê²½ê³  ê°•ë„ ì¡°ì ˆ
        has_significant_change = False
        if analysis.anomaly_analysis.baseline_comparisons:
            has_significant_change = any(
                comp.is_significant_change 
                for comp in analysis.anomaly_analysis.baseline_comparisons
            )
        
        # Alert level ê²°ì •: ìµœê³  ìœ„í—˜ë„ ê¸°ì¤€ìœ¼ë¡œ ë‹¨ì¼í™”
        # urgentê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ urgent
        if max_concern_severity == "urgent" or analysis.comprehensive_summary.priority_level == "ê¸´ê¸‰":
            return StatusOverview(
                alert_level="urgent",
                alert_badge="ğŸš¨",
                alert_title="ì¦‰ì‹œ í™•ì¸ í•„ìš”",
                alert_subtitle="ì–´ë¨¸ë‹ˆê»˜ì„œ ë„ì›€ì´ í•„ìš”í•˜ì‹  ê²ƒ ê°™ìŠµë‹ˆë‹¤",
                status_color="#FF4444"
            )
        elif max_concern_severity == "caution" or (analysis.comprehensive_summary.priority_level == "ì£¼ì˜" and has_significant_change):
            # ì£¼ì˜ëŠ” baseline ë³€í™”ê°€ ìˆì„ ë•Œë§Œ ê°•ì¡°
            return StatusOverview(
                alert_level="caution",
                alert_badge="âš ï¸",
                alert_title="í‰ì†Œì™€ ë‹¤ë¥¸ ì  í™•ì¸",
                alert_subtitle="ì§€ë‚œ 7ì¼ í‰ê·  ëŒ€ë¹„ ë³€í™”ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤",
                status_color="#FF8800"
            )
        elif analysis.comprehensive_summary.priority_level == "ì£¼ì˜":
            # ì£¼ì˜ì´ì§€ë§Œ baseline ë³€í™”ê°€ ì—†ìœ¼ë©´ ê²½ë¯¸í•˜ê²Œ í‘œì‹œ
            return StatusOverview(
                alert_level="normal",
                alert_badge="ğŸ“‹",
                alert_title="ì¼ë°˜ í™•ì¸ ê¶Œì¥",
                alert_subtitle="ì •ê¸°ì ìœ¼ë¡œ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”",
                status_color="#FFAA00"
            )
        else:
            return StatusOverview(
                alert_level="normal",
                alert_badge="ğŸ˜Š",
                alert_title="ì•ˆì •ì ì¸ ìƒíƒœ",
                alert_subtitle="íŠ¹ë³„í•œ ë¬¸ì œëŠ” ì—†ì–´ ë³´ì…ë‹ˆë‹¤",
                status_color="#44FF44"
            )
    
    def _create_today_summary(
        self, 
        analysis: ComprehensiveAnalysisResult, 
        emotional_insights: Dict,
        mother_voice: List[str]
    ) -> TodaySummary:
        """ì˜¤ëŠ˜ ìš”ì•½ ìƒì„± (Baseline ë¹„êµ í¬í•¨)"""
        mood_score = analysis.emotion_analysis.positive
        
        # Baseline ë¹„êµ ì •ë³´ ì¶”ì¶œ
        baseline_info = ""
        if analysis.anomaly_analysis.baseline_comparisons:
            for comp in analysis.anomaly_analysis.baseline_comparisons:
                if comp.metric == "ê¸ì • ê°ì •":
                    baseline_info = f" (í‰ì†Œ í‰ê·  {comp.baseline_average:.0f}ì  ëŒ€ë¹„ {comp.difference:+.0f}ì )"
                    break
        
        if mood_score >= 70:
            mood_label = f"ì¢‹ìŒ{baseline_info}" if baseline_info else "ì¢‹ìŒ"
            mood_emoji = "ğŸ˜Š"
        elif mood_score >= 50:
            mood_label = f"ë³´í†µ{baseline_info}" if baseline_info else "ë³´í†µ"
            mood_emoji = "ğŸ˜"
        elif mood_score >= 30:
            mood_label = f"ìš°ìš¸í•¨{baseline_info}" if baseline_info else "ìš°ìš¸í•¨"
            mood_emoji = "ğŸ˜”"
        else:
            mood_label = f"ë§¤ìš° ìš°ìš¸í•¨{baseline_info}" if baseline_info else "ë§¤ìš° ìš°ìš¸í•¨"
            mood_emoji = "ğŸ˜¢"
        
        # headline ê°œì„ : ê¸´ê¸‰ ê·¼ê±° ì¤‘ì‹¬ (ìš©ì–´Â·í†¤ ì¼ê´€ì„±)
        headline = emotional_insights.get("headline", "ì–´ë¨¸ë‹ˆ ìƒíƒœë¥¼ í™•ì¸í•´ë³´ì„¸ìš”")
        
        # ê¸´ê¸‰í•œ ê²½ìš°(urgent) ê±´ê°• ê´€ë ¨ êµ¬ì²´ì  ê·¼ê±°ë¥¼ headlineì— í¬í•¨
        if analysis.comprehensive_summary.priority_level == "ê¸´ê¸‰":
            urgent_health_issues = []
            health_str = str(analysis.risk_analysis.risk_categories.health)
            safety_str = str(analysis.risk_analysis.risk_categories.safety)
            
            if "ì‹ì‚¬" in health_str or "ë°¥" in health_str or "ìŒì‹" in health_str:
                urgent_health_issues.append("ì‹ì‚¬ëŸ‰ ê°ì†Œ")
            if "í†µì¦" in health_str or "ì•„íŒŒ" in health_str:
                urgent_health_issues.append("í†µì¦")
            if "ë‚™ìƒ" in safety_str:
                urgent_health_issues.append("ë‚™ìƒ ìœ„í—˜")
            
            if urgent_health_issues:
                headline = f"{', '.join(urgent_health_issues)}ê°€ ë™ë°˜ë˜ì–´ ì¦‰ì‹œ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤"
            else:
                headline = "ì¦‰ì‹œ í™•ì¸ì´ í•„ìš”í•œ ìƒíƒœì…ë‹ˆë‹¤"
        
        return TodaySummary(
            headline=headline,
            mood_score=mood_score,
            mood_label=mood_label,
            mood_emoji=mood_emoji,
            energy_score=max(0, 100 - analysis.emotion_analysis.depression),
            pain_score=analysis.emotion_analysis.anxiety,
            mother_voice=mother_voice[:4]  # ìµœëŒ€ 4ê°œ
        )
    
    def _create_detailed_analysis(
        self, 
        analysis: ComprehensiveAnalysisResult, 
        conversation: str,
        audio_analysis: Dict,
        key_concerns: List[KeyConcern]
    ) -> DetailedAnalysis:
        """ìƒì„¸ ë¶„ì„ ìƒì„±"""
        # ëŒ€í™” ì£¼ì œë³„ ìš”ì•½
        topics = []
        if "ì‹ì‚¬" in conversation or "ë°¥" in conversation:
            topics.append(ConversationTopic(
                topic="ì‹ì‚¬",
                summary="ì‹ìš• ê´€ë ¨ ì–¸ê¸‰ì´ ìˆìŠµë‹ˆë‹¤",
                concern_level="caution" if "ì•ˆ ë¨¹" in conversation else "normal"
            ))
        
        # ê°ì • íƒ€ì„ë¼ì¸ (ë”ë¯¸ ë°ì´í„°)
        emotion_timeline = [
            EmotionTimeline(
                timestamp="00:00:30",
                emotion="ë¬´ê¸°ë ¥",
                intensity=75,
                trigger="í”¼ê³¤í•˜ë‹¤ëŠ” ë§ì”€"
            )
        ]
        
        # ìœ„í—˜ ì§€í‘œ (R3: key_concernsì˜ ìµœëŒ€ severity ê¸°ì¤€)
        health_concerns = [c for c in key_concerns if c.type == "ê±´ê°•"]
        mental_concerns = [c for c in key_concerns if c.type == "ì •ì„œ"]
        
        # ìµœëŒ€ severity ì°¾ê¸°
        severity_map = {"urgent": 3, "caution": 2, "normal": 1}
        
        health_max_severity = "normal"
        if health_concerns:
            health_max_severity_value = max(severity_map.get(c.severity, 1) for c in health_concerns)
            health_max_severity = [k for k, v in severity_map.items() if v == health_max_severity_value][0]
        
        mental_max_severity = "normal"
        if mental_concerns:
            mental_max_severity_value = max(severity_map.get(c.severity, 1) for c in mental_concerns)
            mental_max_severity = [k for k, v in severity_map.items() if v == mental_max_severity_value][0]
        
        # severityë¥¼ levelë¡œ ë³€í™˜ (urgent/caution -> high, normal -> medium/low)
        health_level = "high" if health_max_severity == "urgent" else "medium" if health_max_severity == "caution" else "low"
        mental_level = "high" if mental_max_severity == "urgent" else "medium" if mental_max_severity == "caution" else "low"
        
        # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ì™€ ë³‘í•© (ë” ë†’ì€ ë ˆë²¨ ìš°ì„ )
        if analysis.comprehensive_summary.priority_level == "ê¸´ê¸‰" and health_level != "high":
            health_level = "high"
        if analysis.emotion_analysis.depression > 70 and mental_level != "high":
            mental_level = "high"
        
        risk_indicators = {
            "health_risk": RiskIndicator(
                level=health_level,
                factors=analysis.risk_analysis.risk_categories.health
            ),
            "mental_risk": RiskIndicator(
                level=mental_level,
                factors=analysis.risk_analysis.risk_categories.mental
            )
        }
        
        # ì˜ìƒ í•˜ì´ë¼ì´íŠ¸ (ë”ë¯¸)
        video_highlights = [
            VideoHighlight(
                timestamp="00:01:30",
                thumbnail_url="placeholder_thumbnail.jpg",
                emotion="ìš°ìš¸",
                caption="í‘œì •ì´ ì–´ë‘ì›Œ ë³´ì…ë‹ˆë‹¤",
                importance="high"
            )
        ]
        
        # ìŒì„± ë¶„ì„
        audio_analysis_obj = AudioAnalysis(
            voice_energy=audio_analysis.get("voice_energy", "ë³´í†µ"),
            speaking_pace=audio_analysis.get("speaking_pace", "ë³´í†µ"),
            tone_quality=audio_analysis.get("tone_quality", "ë³´í†µ"),
            emotional_indicators=audio_analysis.get("emotional_indicators", [])
        )
        
        return DetailedAnalysis(
            conversation_summary={
                "total_exchanges": len(conversation.split("\n")),
                "conversation_topics": [topic.dict() for topic in topics]
            },
            emotion_timeline=emotion_timeline,
            risk_indicators=risk_indicators,
            video_highlights=video_highlights,
            audio_analysis=audio_analysis_obj
        )
    
    def _create_trend_analysis(self, analysis: ComprehensiveAnalysisResult, baseline_comparison: Optional[Dict]) -> TrendAnalysis:
        """ì¶”ì„¸ ë¶„ì„ ìƒì„± (R5: 7ì¼ ë¯¸ë§Œì´ë©´ ë¹„í™œì„±í™”)"""
        # baseline_comparisonì´ ì—†ê±°ë‚˜ ë°ì´í„° ë¶€ì¡± ì‹œ ë¹„í™œì„±í™”
        if not baseline_comparison or baseline_comparison.get("comparison_period", "").endswith("ë°ì´í„° ë¶€ì¡±"):
            return TrendAnalysis(
                compared_to="ì§€ë‚œ 7ì¼",
                changes=[],
                alert_message="7ì¼ ë¯¸ë§Œ ë°ì´í„°ë¡œ ì‹ ë¢° ë‚®ìŒ",
                pattern="ë°ì´í„° ë¶€ì¡±",
                disabled=True,
                reason="7ì¼ ë¯¸ë§Œ ë°ì´í„°ë¡œ ì‹ ë¢° ë‚®ìŒ"
            )
        
        # baseline_comparisonì—ì„œ ì¶”ì„¸ ë°ì´í„° ìƒì„±
        significant_changes = baseline_comparison.get("significant_changes", [])
        changes = []
        
        for change in significant_changes[:5]:  # ìµœëŒ€ 5ê°œ
            direction = "down" if change.get("difference", 0) < 0 else "up" if change.get("difference", 0) > 0 else "stable"
            icon = "ğŸ“‰" if direction == "down" else "ğŸ“ˆ" if direction == "up" else "â¡ï¸"
            
            changes.append(TrendChange(
                metric=change.get("metric", ""),
                direction=direction,
                change=int(change.get("difference", 0)),
                icon=icon,
                comment=change.get("explanation", "")
            ))
        
        if not changes:
            # ìœ ì˜ë¯¸í•œ ë³€í™”ê°€ ì—†ìœ¼ë©´ ì•ˆì •ì  í‘œì‹œ
            mood_score = analysis.emotion_analysis.positive
            alert_message = "ì§€ë‚œ 7ì¼ ëŒ€ë¹„ í° ë³€í™” ì—†ìŒ"
            if mood_score <= 40:
                alert_message = (
                    f"{alert_message} â€” í˜„ì¬ ê¸°ë¶„ ì ìˆ˜ëŠ” {mood_score}/100ìœ¼ë¡œ ë‚®ì§€ë§Œ "
                    "ì§€ë‚œ 7ì¼ ë™ì•ˆ ë¹„ìŠ·í•œ ìˆ˜ì¤€ì´ ìœ ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ê¸‰ê²©í•œ ì•…í™”ëŠ” ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                )
            return TrendAnalysis(
                compared_to="ì§€ë‚œ 7ì¼",
                changes=[],
                alert_message=alert_message,
                pattern="ì•ˆì •ì "
            )
        
        alert_message = f"âš ï¸ ì§€ë‚œ 7ì¼ ëŒ€ë¹„ {len(changes)}ê°œì˜ ìœ ì˜ë¯¸í•œ ë³€í™”ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤"
        pattern = "ì§€ì†ì  í•˜ë½" if any(c.direction == "down" for c in changes) else "ì§€ì†ì  ìƒìŠ¹" if any(c.direction == "up" for c in changes) else "ë³€ë™"
        
        return TrendAnalysis(
            compared_to="ì§€ë‚œ 7ì¼",
            changes=changes,
            alert_message=alert_message,
            pattern=pattern
        )
    
    def _create_ui_components(
        self, 
        status: StatusOverview, 
        analysis: ComprehensiveAnalysisResult
    ) -> UIComponents:
        """UI ì»´í¬ë„ŒíŠ¸ ìƒì„±"""
        quick_stats = [
            QuickStat(
                label="ê¸°ë¶„",
                value=f"{analysis.emotion_analysis.positive}/100",
                emoji="ğŸ˜¢" if analysis.emotion_analysis.positive < 50 else "ğŸ˜Š",
                color=status.status_color
            ),
            QuickStat(
                label="í™œë ¥",
                value="ë‚®ìŒ" if analysis.emotion_analysis.depression > 50 else "ë³´í†µ",
                emoji="ğŸ˜´",
                color="#FF8800"
            )
        ]
        
        cta_buttons = []
        if analysis.comprehensive_summary.priority_level in ["ê¸´ê¸‰", "ë†’ìŒ"]:
            cta_buttons.append(
                CTAButton(
                    text="ì§€ê¸ˆ ì „í™”í•˜ê¸°",
                    icon="ğŸ“",
                    color="#FF4444",
                    action="call"
                )
            )
        else:
            cta_buttons.append(
                CTAButton(
                    text="ì§§ì€ ì•ˆë¶€ ì „í™”í•˜ê¸°",
                    icon="ğŸ“",
                    color="#FF6666",
                    action="call"
                )
            )

        cta_buttons.append(
            CTAButton(
                text="ìŒì„± ë©”ì‹œì§€ ë³´ë‚´ê¸°",
                icon="ğŸ™ï¸",
                color="#FF8800",
                action="send_voice_note"
            )
        )
        cta_buttons.append(
            CTAButton(
                text="ì˜ìƒ ì „ì²´ë³´ê¸°",
                icon="ğŸ¬",
                color="#4444FF",
                action="watch_video"
            )
        )
        
        if analysis.comprehensive_summary.priority_level == "ê¸´ê¸‰":
            cta_buttons.append(CTAButton(
                text="ë³‘ì› ì˜ˆì•½í•˜ê¸°",
                icon="ğŸ¥",
                color="#FF8800",
                action="book_hospital"
            ))
        
        return UIComponents(
            header={
                "badge_color": status.status_color,
                "badge_text": status.alert_title.split()[0],
                "title": status.alert_subtitle,
                "subtitle": f"ì˜¤ëŠ˜ {datetime.now().strftime('%H:%M')} ì´¬ì˜"
            },
            quick_stats=quick_stats,
            cta_buttons=cta_buttons
        )
    
    def _create_default_action_plan(self, analysis: ComprehensiveAnalysisResult) -> ActionPlan:
        """ê¸°ë³¸ í–‰ë™ ê³„íš ìƒì„±"""
        urgent_actions = [
            UrgentAction(
                action_id=1,
                priority="ìµœìš°ì„ ",
                icon="ğŸ“",
                title="ì–´ë¨¸ë‹ˆê»˜ ì§§ê²Œ ì•ˆë¶€ ì „í™” ë“œë¦¬ê¸°",
                reason="ì˜¤ëŠ˜ ê¸°ë¶„ê³¼ ëª¸ ìƒíƒœë¥¼ ì§ì ‘ í™•ì¸í•˜ë©´ ì•ˆì‹¬í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤",
                detail="5ë¶„ ì •ë„ í†µí™”í•˜ë©´ì„œ í˜„ì¬ ì»¨ë””ì…˜ê³¼ í•„ìš”í•œ ë„ì›€ì´ ìˆëŠ”ì§€ ì—¬ì­¤ë³´ì„¸ìš”",
                deadline="ì˜¤ëŠ˜ ì¤‘",
                estimated_time="10ë¶„ ì´ë‚´",
                suggested_topics=[
                    "ì§€ê¸ˆ ì–´ë”” ë¶ˆí¸í•˜ì‹  ê³³ì€ ì—†ëŠ”ì§€ í¸í•˜ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”",
                    "ì‹ì‚¬ë‚˜ ì•½ ì±™ê¸°ì‹œëŠ” ë° ë„ì™€ë“œë¦´ ì¼ ìˆì„ê¹Œìš”?",
                    "ì´ë²ˆ ì£¼ í›„ë°˜ì— ì œê°€ ë“¤ë¥¼ ìˆ˜ ìˆëŠ”ë° ê´œì°®ìœ¼ì„¸ìš”?"
                ]
            ),
            UrgentAction(
                action_id=2,
                priority="ê¸´ê¸‰",
                icon="ğŸ¥",
                title="ì§§ì€ ì˜ìƒ í†µí™” ì‹œê°„ ì¡ê¸°",
                reason="ì–¼êµ´ì„ ë³´ê³  ì´ì•¼ê¸°í•˜ë©´ ì •ì„œì  ì•ˆì •ì— ë„ì›€ì´ ë©ë‹ˆë‹¤",
                detail="ëŠ¦ì§€ ì•Šì€ ì‹œê°„ì— 10ë¶„ ì •ë„ ì˜ìƒ í†µí™”ë¥¼ ì œì•ˆí•´ë³´ì„¸ìš”",
                deadline="ì˜¤ëŠ˜ ì¤‘",
                estimated_time="5-10ë¶„",
                suggested_topics=[
                    "ì–¼êµ´ ëµ™ê³  ë°”ë¡œ ì•ˆë¶€ ì—¬ì­¤ë³´ê³  ì‹¶ì–´ìš”, ê´œì°®ìœ¼ì„¸ìš”?",
                    "ìš”ì¦˜ ì§‘ì•ˆì— ë°”ë€ ì ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•˜ì‹  ê²Œ ìˆëŠ”ì§€ ë´ë“œë¦´ê²Œìš”",
                    "ë‹¤ìŒì— í•¨ê»˜ í•˜ê³  ì‹¶ì€ í™œë™ ìˆìœ¼ë©´ ë§ì”€í•´ì£¼ì„¸ìš”"
                ]
            ),
        ]
        
        this_week_actions = [
            UrgentAction(
                action_id=3,
                priority="ì¤‘ìš”",
                icon="ğŸ™ï¸",
                title="ìŒì„± ë©”ì‹œì§€ë¡œ ì‘ì› ë‚¨ê¸°ê¸°",
                reason="í†µí™”ê°€ ì–´ë ¤ìš´ ë‚ ì—ë„ ê¾¸ì¤€í•œ ì •ì„œì  ì—°ê²°ì„ ìœ ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤",
                detail="ì˜¤ëŠ˜ ë“¤ì€ ì´ì•¼ê¸°ë‚˜ ì‘ì›ì˜ ë§ì„ ì§§ê²Œ ë…¹ìŒí•´ ë³´ë‚´ì£¼ì„¸ìš”",
                deadline="ì´ë²ˆ ì£¼",
                estimated_time="5ë¶„",
                suggested_topics=[
                    "ì˜¤ëŠ˜ ìˆì—ˆë˜ ê¸°ë¶„ ì¢‹ì€ ì¼ì´ë‚˜ ê°ì‚¬ ì¸ì‚¬ë¥¼ ì „í•´ì£¼ì„¸ìš”",
                    "ì–´ë¨¸ë‹ˆê»˜ì„œ ì¢‹ì•„í•˜ì‹œëŠ” ë…¸ë˜ í•œ ì†Œì ˆì„ ë¶ˆëŸ¬ë“œë ¤ë„ ì¢‹ì•„ìš”"
                ]
            ),
            UrgentAction(
                action_id=4,
                priority="ì¤‘ìš”",
                icon="ğŸš¶",
                title="ê·¼ì²˜ ë³µì§€ì„¼í„° ì‚°ì±… í”„ë¡œê·¸ë¨ ë¬¸ì˜í•˜ê¸°",
                reason="ê·œì¹™ì ì¸ ì™¸ì¶œê³¼ ì‚¬íšŒì  êµë¥˜ëŠ” ê¸°ë¶„ íšŒë³µì— í° ë„ì›€ì´ ë©ë‹ˆë‹¤",
                detail="ì–´ë¨¸ë‹ˆì™€ í•¨ê»˜ ì°¸ì—¬í•  ìˆ˜ ìˆëŠ” ê°€ë²¼ìš´ ì‚°ì±… ë˜ëŠ” ìš´ë™ í”„ë¡œê·¸ë¨ì„ ì•Œì•„ë³´ì„¸ìš”",
                deadline="ì´ë²ˆ ì£¼",
                estimated_time="20ë¶„",
                suggested_topics=[
                    "ë‚ ì”¨ ì¢‹ì€ ë‚  ê°™ì´ ê±¸ì„ ìˆ˜ ìˆëŠ” í”„ë¡œê·¸ë¨ì´ ìˆëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”",
                    "ì°¸ì—¬ ì‹œ í•„ìš”í•œ ì¤€ë¹„ë¬¼ì´ë‚˜ ì¼ì •ë„ í•¨ê»˜ ì •ë¦¬í•´ì£¼ì„¸ìš”"
                ]
            )
        ]
        
        return ActionPlan(
            urgent_actions=urgent_actions,
            this_week_actions=this_week_actions,
            long_term_actions=[]
        )
    
    def _create_default_concerns(self, analysis: ComprehensiveAnalysisResult) -> List[KeyConcern]:
        """ê¸°ë³¸ ê±±ì •ê±°ë¦¬ ìƒì„±"""
        concerns = []
        
        if analysis.emotion_analysis.depression > 70:
            concerns.append(KeyConcern(
                concern_id=1,
                type="ì •ì„œ",
                icon="ğŸ’”",
                severity="caution",
                title="ìš°ìš¸í•œ ê¸°ë¶„",
                description="í‰ì†Œë³´ë‹¤ ê¸°ë¶„ì´ ë§ì´ ê°€ë¼ì•‰ì•„ ìˆìœ¼ì‹  ê²ƒ ê°™ìŠµë‹ˆë‹¤. ê´€ì‹¬ì„ ë” ê¸°ìš¸ì—¬ì£¼ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤",
                detected_from=["ëŒ€í™”", "í‘œì •"],
                urgency_reason="ìš°ìš¸ê° ì•…í™” ê°€ëŠ¥ì„±"
            ))
        
        if analysis.emotion_analysis.loneliness > 70:
            concerns.append(KeyConcern(
                concern_id=2,
                type="ì •ì„œ",
                icon="ğŸ‘¥",
                severity="caution",
                title="ì™¸ë¡œì›€",
                description="í˜¼ì ê³„ì‹œëŠ” ì‹œê°„ì´ ë§ì•„ ì™¸ë¡œì›Œí•˜ì‹œëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤. ì´ë²ˆ ì£¼ë§ì— ì‹œê°„ ë‚´ì–´ ë°©ë¬¸í•´ì£¼ì‹œë©´ ì¢‹ê² ìŠµë‹ˆë‹¤",
                detected_from=["ëŒ€í™”"],
                urgency_reason="ì‚¬íšŒì  ê³ ë¦½ ìš°ë ¤"
            ))
        
        return concerns
    
    def _create_evidence_visualization(
        self,
        analysis: ComprehensiveAnalysisResult,
        conversation: str,
        audio_analysis: Dict,
        image_analysis: Dict,
        key_concerns: List[KeyConcern]
    ) -> EvidenceVisualization:
        """ê·¼ê±° ì‹œê°í™” ë°ì´í„° ìƒì„±"""
        emotion_evidence = analysis.emotion_analysis.evidence
        
        # ê°ì • í‚¤ì›Œë“œ ì¶”ì¶œ
        emotion_keywords = []
        keyword_weights = {}
        
        if emotion_evidence:
            all_keywords = emotion_evidence.detected_keywords
            emotion_keywords = all_keywords[:10]  # ìµœëŒ€ 10ê°œ
            
            # í‚¤ì›Œë“œë³„ ê°€ì¤‘ì¹˜ ê°œì„ : ë¹ˆë„Ã—ê°•ë„Ã—ìµœê·¼ì„± (R6)
            keyword_counts = {}
            for keyword in all_keywords:
                keyword_counts[keyword] = keyword_counts.get(keyword, 0) + 1
            
            # ê°ì • ê°•ë„ ë§¤í•‘ (ë†’ì„ìˆ˜ë¡ ì¤‘ìš”)
            emotion_intensity = {
                "ìš°ìš¸": 0.9, "ìŠ¬í””": 0.8, "ì™¸ë¡œì›€": 0.7, "ë¶ˆì•ˆ": 0.8, "ë¶„ë…¸": 0.7,
                "ë¬´ê¸°ë ¥": 0.6, "í”¼ê³¤": 0.5, "í–‰ë³µ": 0.3, "ê¸°ì¨": 0.3
            }
            
            # ê°€ì¤‘ì¹˜ ê³„ì‚°: ë¹ˆë„ Ã— ê°•ë„ (ìµœê·¼ì„±ì€ ì¼ë‹¨ ìƒëµ)
            raw_weights = {}
            for keyword, count in keyword_counts.items():
                intensity = emotion_intensity.get(keyword, 0.5)
                raw_weights[keyword] = count * intensity
            
            # Softmax ì •ê·œí™” (í•© = 1)
            total_weight = sum(raw_weights.values())
            if total_weight > 0:
                for keyword, weight in raw_weights.items():
                    keyword_weights[keyword] = weight / total_weight
            else:
                for keyword in all_keywords:
                    keyword_weights[keyword] = 1.0 / len(all_keywords) if all_keywords else 0.0
        
        # í‘œì • ë³€í™” íƒ€ì„ë¼ì¸ (ì‹ ë¢°ë„ ê¸°ì¤€ í•„í„°ë§)
        facial_timeline = []
        confidence_threshold = 60  # 60% ë¯¸ë§Œì´ë©´ ê°ì • ë¯¸ê²€ì¶œë¡œ ì²˜ë¦¬
        if image_analysis.get("analysis"):
            img_data = image_analysis["analysis"]
            emotions = img_data.get("emotion", [])
            confidence = image_analysis.get("confidence", 0)
            
            # confidenceê°€ ë‚®ìœ¼ë©´ ê°ì • ë¯¸ê²€ì¶œ ì²˜ë¦¬
            if confidence >= confidence_threshold and emotions:
                # í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°ì • ì¶”ì¶œ (ëŒ€í™” ë§¥ë½)
                text_emotions = set()
                if emotion_evidence and emotion_evidence.detected_keywords:
                    for kw in emotion_evidence.detected_keywords:
                        if "ìš°ìš¸" in kw or "ìŠ¬í””" in kw:
                            text_emotions.add("ìš°ìš¸")
                        elif "í”¼ê³¤" in kw or "ë¬´ê¸°ë ¥" in kw:
                            text_emotions.add("ë¬´ê¸°ë ¥")
                        elif "ì™¸ë¡œì›€" in kw:
                            text_emotions.add("ì™¸ë¡œì›€")
                        elif "ë¶„ë…¸" in kw or "í™”" in kw:
                            text_emotions.add("ë¶„ë…¸")
                
                for i, emotion in enumerate(emotions[:5]):  # ìµœëŒ€ 5ê°œ
                    # ê° ê°ì •ë³„ confidence ê³„ì‚° (ì „ì²´ confidenceë¥¼ ê¸°ë°˜ìœ¼ë¡œ)
                    emotion_confidence = max(confidence_threshold, confidence - (i * 5))
                    
                    # ë§¥ë½ ì¶©ëŒ ê°ì§€ (R4): í…ìŠ¤íŠ¸ì™€ í‘œì • ë¶ˆì¼ì¹˜ ì²´í¬
                    context_mismatch = False
                    if text_emotions and emotion not in text_emotions:
                        # ì˜ˆ: í‘œì •ì€ ë¶„ë…¸ì¸ë° í…ìŠ¤íŠ¸ëŠ” ìš°ìš¸/í”¼ê³¤
                        if emotion == "ë¶„ë…¸" and ("ìš°ìš¸" in text_emotions or "ë¬´ê¸°ë ¥" in text_emotions):
                            context_mismatch = True
                        elif emotion in ["ê¸°ì¨", "í–‰ë³µ"] and ("ìš°ìš¸" in text_emotions or "ì™¸ë¡œì›€" in text_emotions):
                            context_mismatch = True
                    
                    reliability = "ë†’ìŒ" if emotion_confidence >= 80 else "ë³´í†µ" if emotion_confidence >= 60 else "ë‚®ìŒ"
                    if context_mismatch:
                        reliability = "ë³´ë¥˜"
                    
                    facial_timeline.append({
                        "timestamp": f"00:0{i*10}:00",
                        "emotion": emotion,
                        "confidence": emotion_confidence,
                        "reliability": reliability,
                        "note": "í…ìŠ¤íŠ¸/ìŒì„± ë§¥ë½ê³¼ ë¶ˆì¼ì¹˜í•˜ì—¬ ê²€ì¦ í•„ìš”" if context_mismatch else None
                    })
            else:
                # confidenceê°€ ë‚®ìœ¼ë©´ ê°ì • ë¯¸ê²€ì¶œë¡œ í‘œì‹œ
                facial_timeline.append({
                    "timestamp": "00:00:00",
                    "emotion": "ê°ì • ë¯¸ê²€ì¶œ",
                    "confidence": confidence,
                    "reliability": "ë‚®ìŒ",
                    "note": f"í‘œì • ë¶„ì„ í™•ì‹¤ë„ {confidence}%ë¡œ ì‹ ì¤‘í•œ í•´ì„ì´ í•„ìš”í•©ë‹ˆë‹¤"
                })
        
        # ìŒì„± ì—ë„ˆì§€ íŒŒí˜• ë°ì´í„° (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        voice_waveform = None
        if audio_analysis.get("shout_detection"):
            shout_data = audio_analysis["shout_detection"]
            voice_waveform = {
                "average_energy": shout_data.get("average_energy", 0.5),
                "max_energy": shout_data.get("max_energy", 0.7),
                "detected_shout": shout_data.get("detected_shout", False),
                "energy_level": "ë†’ìŒ" if shout_data.get("average_energy", 0.5) > 0.6 else "ë³´í†µ"
            }
        
        # ì ìˆ˜ë³„ ì„¸ë¶€ ë¶„ì„
        score_breakdown = {}
        if emotion_evidence:
            score_breakdown = {
                "positive": {
                    "score": analysis.emotion_analysis.positive,
                    "factors": emotion_evidence.positive_factors[:3],
                    "explanation": f"ê¸ì • ì ìˆ˜ëŠ” {', '.join(emotion_evidence.positive_factors[:2])} ë“±ì˜ ìš”ì¸ìœ¼ë¡œ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤" if emotion_evidence.positive_factors else "ê¸ì •ì  í‘œí˜„ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
                },
                "depression": {
                    "score": analysis.emotion_analysis.depression,
                    "factors": emotion_evidence.depression_factors[:3],
                    "explanation": f"ìš°ìš¸ ì ìˆ˜ëŠ” {', '.join(emotion_evidence.depression_factors[:2])} ë“±ì˜ ìš”ì¸ìœ¼ë¡œ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤" if emotion_evidence.depression_factors else "ìš°ìš¸ ì§€í‘œê°€ ë‚®ìŠµë‹ˆë‹¤"
                },
                "anxiety": {
                    "score": analysis.emotion_analysis.anxiety,
                    "factors": emotion_evidence.anxiety_factors[:3],
                    "explanation": f"ë¶ˆì•ˆ ì ìˆ˜ëŠ” {', '.join(emotion_evidence.anxiety_factors[:2])} ë“±ì˜ ìš”ì¸ìœ¼ë¡œ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤" if emotion_evidence.anxiety_factors else "ë¶ˆì•ˆ ì§€í‘œê°€ ë‚®ìŠµë‹ˆë‹¤"
                }
            }
        else:
            # evidenceê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
            score_breakdown = {
                "positive": {
                    "score": analysis.emotion_analysis.positive,
                    "factors": [],
                    "explanation": "ëŒ€í™” ë‚´ìš© ë¶„ì„ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤"
                },
                "depression": {
                    "score": analysis.emotion_analysis.depression,
                    "factors": [],
                    "explanation": "ëŒ€í™” ë‚´ìš© ë¶„ì„ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤"
                }
            }
        
        # ë©€í‹°ëª¨ë‹¬ ì‹ ë¢°ë„ ê°€ì¤‘ í‰ê·  ê³„ì‚° (R4)
        text_confidence = 0.75  # í…ìŠ¤íŠ¸ ë¶„ì„ ê¸°ë³¸ ì‹ ë¢°ë„
        audio_confidence = 0.65 if audio_analysis.get("shout_detection") else 0.60
        face_confidence = image_analysis.get("confidence", 0) / 100.0 if image_analysis.get("analysis") else 0
        
        # ê°€ì¤‘ì¹˜: text 0.6, audio 0.25, face 0.15
        w_text, w_audio, w_face = 0.6, 0.25, 0.15
        overall_confidence = (w_text * text_confidence + w_audio * audio_confidence + w_face * face_confidence) * 100
        
        # ê³„ì‚° ë°©ë²• ì„¤ëª… + ë©€í‹°ëª¨ë‹¬ í™•ì‹¤ë„ í‘œì‹œ
        calculation_method = f"ê°ì • ì ìˆ˜ëŠ” ëŒ€í™” ë‚´ìš©(ê°€ì¤‘ì¹˜ 60%), ìŒì„± í†¤(ê°€ì¤‘ì¹˜ 25%), í‘œì • ë¶„ì„(ê°€ì¤‘ì¹˜ 15%)ì„ ì¢…í•©í•˜ì—¬ ê³„ì‚°í•©ë‹ˆë‹¤. "
        calculation_method += f"ì „ì²´ ì‹ ë¢°ë„: {overall_confidence:.1f}% (í…ìŠ¤íŠ¸ {text_confidence*100:.0f}%, ìŒì„± {audio_confidence*100:.0f}%, í‘œì • {face_confidence*100:.0f}%). "
        calculation_method += "ê° ì ìˆ˜ëŠ” 0-100 ë²”ìœ„ì´ë©°, ì—¬ëŸ¬ ìš”ì¸ì„ ê³ ë ¤í•˜ì—¬ ê²°ì •ë©ë‹ˆë‹¤."
        
        if emotion_evidence and emotion_evidence.facial_expression_notes:
            calculation_method += f" í‘œì • ë¶„ì„ ê²°ê³¼: '{emotion_evidence.facial_expression_notes[:50]}...'"
        
        return EvidenceVisualization(
            emotion_keywords=emotion_keywords,
            keyword_weights=keyword_weights,
            facial_expression_timeline=facial_timeline,
            voice_energy_waveform=voice_waveform,
            score_breakdown=score_breakdown,
            calculation_method=calculation_method
        )
    
    def _create_baseline_comparison(self, analysis: ComprehensiveAnalysisResult) -> Optional[Dict]:
        """Baseline ë¹„êµ ë°ì´í„° ìƒì„± (ëª…í™•í•œ í‘œí˜„ í•„ìˆ˜ í¬í•¨)"""
        baseline_comparisons = analysis.anomaly_analysis.baseline_comparisons
        
        # baseline_comparisonsê°€ ì—†ì–´ë„ ê¸°ë³¸ ì •ë³´ëŠ” ì œê³µ
        if not baseline_comparisons:
            # í˜„ì¬ ê°’ë§Œì´ë¼ë„ í‘œì‹œ
            return {
                "comparison_period": "ì§€ë‚œ 7ì¼ (ë°ì´í„° ë¶€ì¡±)",
                "current_values": {
                    "ê¸ì • ê°ì •": analysis.emotion_analysis.positive,
                    "ìš°ìš¸ ê°ì •": analysis.emotion_analysis.depression,
                    "ì™¸ë¡œì›€ ê°ì •": analysis.emotion_analysis.loneliness
                },
                "summary": "ê³¼ê±° ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ê°œì¸ í‰ê·  ë¹„êµëŠ” ì–´ë µìŠµë‹ˆë‹¤. í˜„ì¬ ìƒíƒœë§Œ í™•ì¸ë©ë‹ˆë‹¤.",
                "note": "ì¼ì£¼ì¼ ì´ìƒ ë°ì´í„°ê°€ ìŒ“ì´ë©´ ê°œì¸ í‰ê·  ëŒ€ë¹„ ë³€í™”ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            }
        
        # ëª¨ë“  ë³€í™” í¬í•¨ (ìœ ì˜ë¯¸í•œ ê²ƒê³¼ ì•„ë‹Œ ê²ƒ êµ¬ë¶„)
        all_changes = []
        significant_changes = []
        
        for comp in baseline_comparisons:
            change_data = {
                "metric": comp.metric,
                "current": comp.current_value,
                "baseline": comp.baseline_average,
                "difference": comp.difference,
                "difference_pct": comp.difference_percentage,
                "is_significant": comp.is_significant_change,
                "explanation": f"í‰ì†Œ í‰ê·  {comp.baseline_average:.1f}ì  â†’ ì˜¤ëŠ˜ {comp.current_value:.1f}ì  ({comp.difference:+.1f}ì , {comp.difference_percentage:+.1f}%)"
            }
            all_changes.append(change_data)
            if comp.is_significant_change:
                significant_changes.append(change_data)
        
        # ê°€ì¥ ì¤‘ìš”í•œ ë³€í™” ì¶”ì¶œ (ê¸ì • ê°ì • ë˜ëŠ” ìš°ìš¸ ê°ì •)
        mood_change = None
        for comp in baseline_comparisons:
            if comp.metric in ["ê¸ì • ê°ì •", "ìš°ìš¸ ê°ì •"]:
                mood_change = f"í‰ì†Œ í‰ê·  {comp.baseline_average:.0f}ì  â†’ ì˜¤ëŠ˜ {comp.current_value:.0f}ì  ({comp.difference:+.0f}ì  ê°ì†Œ)" if comp.difference < 0 else f"í‰ì†Œ í‰ê·  {comp.baseline_average:.0f}ì  â†’ ì˜¤ëŠ˜ {comp.current_value:.0f}ì  ({comp.difference:+.0f}ì  ì¦ê°€)"
                break
        
        summary = ""
        if significant_changes:
            summary = f"ì§€ë‚œ 7ì¼ í‰ê·  ëŒ€ë¹„ {len(significant_changes)}ê°œì˜ ìœ ì˜ë¯¸í•œ ë³€í™”ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. "
            if mood_change:
                summary += mood_change
        else:
            summary = "ì§€ë‚œ 7ì¼ í‰ê·  ëŒ€ë¹„ í° ë³€í™”ê°€ ì—†ìŠµë‹ˆë‹¤."
            if mood_change:
                summary += f" ({mood_change})"
        
        return {
            "comparison_period": "ì§€ë‚œ 7ì¼",
            "all_changes": all_changes,
            "significant_changes": significant_changes,
            "summary": summary,
            "mood_comparison": mood_change  # ê°€ì¥ ì¤‘ìš”í•œ ë¹„êµ ì •ë³´
        }
    
    def _create_medical_disclaimer(
        self, 
        analysis: ComprehensiveAnalysisResult, 
        action_plan: ActionPlan,
        key_concerns: List[KeyConcern]
    ) -> MedicalDisclaimer:
        """ì˜ë£Œ ì±…ì„ ë©´ì±… ì¡°í•­ ìƒì„± (R2: action_planê³¼ ì¼ì¹˜)"""
        # ê³ ì • ë©´ì±… ì¡°í•­
        disclaimer_text = (
            "ë³¸ ë¶„ì„ ê²°ê³¼ëŠ” ì°¸ê³ ìš© ì •ë³´ì´ë©°, ì˜ë£Œ ì§„ë‹¨ì´ ì•„ë‹™ë‹ˆë‹¤. "
            "ìš°ë ¤ê°€ ì§€ì†ë˜ë©´ ì˜ë£Œì§„ê³¼ ìƒë‹´í•˜ì„¸ìš”."
        )
        
        # action_planì˜ urgent_actionsì—ì„œ ê±´ê°• ê´€ë ¨ ì•¡ì…˜ í™•ì¸
        health_urgent_actions = []
        health_keywords = ["ì˜ì‚¬", "ë³‘ì›", "ìƒë‹´", "ì§„ë£Œ", "ì•½", "ì¦ìƒ", "í†µì¦", "ì‹ì‚¬", "ìŒì‹"]
        
        for action in action_plan.urgent_actions:
            if any(keyword in action.title or keyword in action.detail for keyword in health_keywords):
                health_urgent_actions.append(action)
        
        # key_concernsì—ì„œ ê±´ê°• ê´€ë ¨ urgent í™•ì¸
        health_urgent_concerns = [c for c in key_concerns if c.type == "ê±´ê°•" and c.severity == "urgent"]
        
        # suggested_action ìƒì„± (R2: action_planê³¼ ì¼ì¹˜)
        if health_urgent_actions or health_urgent_concerns:
            # urgent ì•¡ì…˜ì´ ìˆìœ¼ë©´ êµ¬ì²´ì ìœ¼ë¡œ í‘œì‹œ
            action_titles = [a.title for a in health_urgent_actions[:2]]
            if action_titles:
                suggested_action = f"ì´ë²ˆ ì£¼ ë‚´ ê°€ë²¼ìš´ ì§„ë£Œ ì˜ˆì•½ ê¶Œì¥ ({', '.join(action_titles[:2])})"
            else:
                concern_titles = [c.title for c in health_urgent_concerns[:2]]
                suggested_action = f"ì´ë²ˆ ì£¼ ë‚´ ê°€ë²¼ìš´ ì§„ë£Œ ì˜ˆì•½ ê¶Œì¥ ({', '.join(concern_titles[:2])})"
        else:
            # ì¼ë°˜ì ì¸ ê±´ê°• ê´€ë ¨ ê¶Œì¥ì‚¬í•­ë§Œ ìˆëŠ” ê²½ìš°
            has_health_mention = any(keyword in action.title for action in action_plan.this_week_actions for keyword in health_keywords)
            if has_health_mention:
                suggested_action = "ê±´ê°• ê´€ë ¨ ìš°ë ¤ì‚¬í•­ì´ ìˆìœ¼ë‹ˆ ì˜ë£Œì§„ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
            else:
                suggested_action = "í˜„ì¬ ê±´ê°• ê´€ë ¨ ê¶Œì¥ì‚¬í•­ì€ ì—†ìŠµë‹ˆë‹¤."
        
        return MedicalDisclaimer(
            disclaimer_text=disclaimer_text,
            is_recommendation_not_diagnosis=True,
            suggested_action=suggested_action
        )
