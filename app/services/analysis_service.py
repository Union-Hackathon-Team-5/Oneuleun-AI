import asyncio
import json
import logging
import os
import time
from typing import Any, Dict, List, Optional, Tuple
from datetime import datetime, timedelta

import httpx
from pydantic import ValidationError

from app.models.analysis_models import (
    EmotionAnalysis, ContentAnalysis, RiskAnalysis, AnomalyAnalysis,
    ComprehensiveAnalysisResult, ComprehensiveSummary, EmotionScore,
    EmotionEvidence, BaselineComparison
)

logger = logging.getLogger(__name__)


class AnalysisService:
    """ë³‘ë ¬ OpenAI API í˜¸ì¶œì„ í†µí•œ ì˜ìƒ í¸ì§€ ì¢…í•© ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY environment variable is required")
        
        self.api_key = api_key
        self.model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
        self.base_url = "https://api.openai.com/v1/chat/completions"
        self._client: Optional[httpx.AsyncClient] = None
    
    async def _get_client(self) -> httpx.AsyncClient:
        if self._client is None:
            # ì—°ê²° í’€ì„ ëŠ˜ë ¤ì„œ ë³‘ë ¬ ìš”ì²­ì„ ë³´ì¥
            # íƒ€ì„ì•„ì›ƒì„ 15ì´ˆë¡œ ì¤„ì—¬ì„œ ë¹ ë¥¸ ì‹¤íŒ¨ ë³´ì¥
            limits = httpx.Limits(max_keepalive_connections=20, max_connections=20)
            timeout = httpx.Timeout(15.0, connect=5.0)  # ì´ 15ì´ˆ, ì—°ê²° 5ì´ˆ
            self._client = httpx.AsyncClient(timeout=timeout, limits=limits)
        return self._client
    
    async def _call_openai(self, prompt: str, max_tokens: int = 800, task_name: str = "unknown", timeout_seconds: float = 15.0) -> str:
        """OpenAI API í˜¸ì¶œ (JSON í˜•ì‹ ê°•ì œ, ìµœì í™”, íƒ€ì„ì•„ì›ƒ ì ìš©)"""
        call_start = time.time()
        print(f"[PERF] Starting API call: {task_name} (tokens: {max_tokens})", flush=True)
        
        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë…¸ì¸ ë³µì§€ ì „ë¬¸ AI ë¶„ì„ì‚¬ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.1,
            "max_tokens": max_tokens,
            "response_format": {"type": "json_object"}
        }
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }
        
        try:
            client = await self._get_client()
            api_start = time.time()
            # asyncio.wait_forë¡œ ê°œë³„ ì‘ì—… íƒ€ì„ì•„ì›ƒ ê°•ì œ
            response = await asyncio.wait_for(
                client.post(self.base_url, headers=headers, json=payload),
                timeout=timeout_seconds
            )
            api_time = time.time() - api_start
            response.raise_for_status()
            data = response.json()
            result = data["choices"][0]["message"]["content"].strip()
            total_time = time.time() - call_start
            print(f"[PERF] Completed API call: {task_name} - {api_time:.2f}s (total: {total_time:.2f}s, tokens: {max_tokens})", flush=True)
            logger.debug(f"[PERF] OpenAI API call: {api_time:.2f}s (total: {total_time:.2f}s, tokens: {max_tokens})")
            return result
        except asyncio.TimeoutError:
            logger.error(f"OpenAI API call timeout: {task_name} (>{timeout_seconds}s)")
            raise RuntimeError(f"{task_name} í˜¸ì¶œì´ {timeout_seconds}ì´ˆ ë‚´ì— ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.") from None
        except Exception as exc:
            logger.error("OpenAI API call failed: %s", exc)
            raise
    
    async def analyze_emotion_state(self, conversation: str, image_analysis: Optional[Dict] = None) -> EmotionAnalysis:
        """ê°ì • ìƒíƒœ ë¶„ì„ (ëŒ€í™” + ì´ë¯¸ì§€ ë¶„ì„ ì¢…í•©) + ê·¼ê±° í¬í•¨"""
        
        # ì´ë¯¸ì§€ ë¶„ì„ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©
        image_context = ""
        facial_notes = ""
        if image_analysis and "analysis" in image_analysis:
            img_data = image_analysis["analysis"]
            emotions = ", ".join(img_data.get("emotion", []))
            summary = img_data.get("summary", "")
            concerns = img_data.get("concerns", [])
            
            image_context = f"""

ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼:
- ê°ì •: {emotions}
- í‘œì • ì„¤ëª…: {summary}
- ìš°ë ¤ì‚¬í•­: {", ".join(concerns) if concerns else "ì—†ìŒ"}
"""
            facial_notes = summary
        
        prompt = f"""
ë‹¤ìŒ ë…ê±°ë…¸ì¸ê³¼ AIì˜ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ì—¬ ê°ì • ìƒíƒœë¥¼ íŒŒì•…í•˜ê³ , ê° ì ìˆ˜ê°€ ì™œ ê·¸ë ‡ê²Œ ê³„ì‚°ë˜ì—ˆëŠ”ì§€ êµ¬ì²´ì ì¸ ê·¼ê±°ë¥¼ í•¨ê»˜ ì œê³µí•´ì£¼ì„¸ìš”.

ëŒ€í™” ë‚´ìš©:
{conversation}
{image_context}

ìœ„ ëŒ€í™” ë‚´ìš©ê³¼ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "positive": <0-100 ê¸ì • ì ìˆ˜>,
    "negative": <0-100 ë¶€ì • ì ìˆ˜>,
    "anxiety": <0-100 ë¶ˆì•ˆ ì ìˆ˜>,
    "depression": <0-100 ìš°ìš¸ ì ìˆ˜>,
    "loneliness": <0-100 ì™¸ë¡œì›€ ì ìˆ˜>,
    "overall_mood": "<ì „ë°˜ì  ê¸°ë¶„: ë§¤ìš°ì¢‹ìŒ/ì¢‹ìŒ/ë³´í†µ/ë‚˜ì¨/ë§¤ìš°ë‚˜ì¨>",
    "emotional_summary": "<í•œ ë¬¸ì¥ ê°ì • ìš”ì•½>",
    "evidence": {{
        "positive_factors": ["<ê¸ì • ì ìˆ˜ì— ê¸°ì—¬í•œ ëŒ€í™” ë‚´ìš©ì´ë‚˜ í‘œí˜„ë“¤>", ...],
        "negative_factors": ["<ë¶€ì • ì ìˆ˜ì— ê¸°ì—¬í•œ ëŒ€í™” ë‚´ìš©ì´ë‚˜ í‘œí˜„ë“¤>", ...],
        "anxiety_factors": ["<ë¶ˆì•ˆ ì ìˆ˜ì— ê¸°ì—¬í•œ ìš”ì¸ë“¤>", ...],
        "depression_factors": ["<ìš°ìš¸ ì ìˆ˜ì— ê¸°ì—¬í•œ ìš”ì¸ë“¤>", ...],
        "loneliness_factors": ["<ì™¸ë¡œì›€ ì ìˆ˜ì— ê¸°ì—¬í•œ ìš”ì¸ë“¤>", ...],
        "detected_keywords": ["<ëŒ€í™”ì—ì„œ ê°ì§€ëœ ê°ì • í‚¤ì›Œë“œë“¤>", ...]
    }}
}}

ì¤‘ìš”: ê° ì ìˆ˜ì— ëŒ€í•´ êµ¬ì²´ì ì¸ ê·¼ê±°ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ positive=20ì´ë©´ "ì–´ë–¤ ëŒ€í™”ì—ì„œ ê·¸ëŸ° ì ìˆ˜ê°€ ë‚˜ì™”ëŠ”ì§€" ëª…í™•íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.
"""
        
        try:
            response = await self._call_openai(prompt, max_tokens=800, task_name="analyze_emotion_state")
            data = json.loads(response)
            
            # evidence ì²˜ë¦¬
            evidence_data = data.get("evidence", {})
            if facial_notes and evidence_data:
                evidence_data["facial_expression_notes"] = facial_notes
            
            # evidenceë¥¼ ë¨¼ì € ì²˜ë¦¬
            evidence_obj = None
            if evidence_data:
                evidence_obj = EmotionEvidence.model_validate(evidence_data)
            
            # model_validateë¡œ ì§ì ‘ íŒŒì‹± (ìµœì í™”)
            emotion_data = {
                "positive": data.get("positive", 50),
                "negative": data.get("negative", 50),
                "anxiety": data.get("anxiety", 50),
                "depression": data.get("depression", 50),
                "loneliness": data.get("loneliness", 50),
                "overall_mood": data.get("overall_mood", "ë³´í†µ"),
                "emotional_summary": data.get("emotional_summary", "ë¶„ì„ ì‹¤íŒ¨"),
                "evidence": evidence_obj
            }
            return EmotionAnalysis.model_validate(emotion_data)
        except (json.JSONDecodeError, ValidationError) as exc:
            logger.error("Failed to parse emotion analysis response: %s", exc)
            return EmotionAnalysis(
                positive=50, negative=50, anxiety=50, 
                depression=50, loneliness=50,
                overall_mood="ë³´í†µ",
                emotional_summary="ë¶„ì„ ì‹¤íŒ¨",
                evidence=None
            )
    
    async def analyze_conversation_content(self, conversation: str) -> ContentAnalysis:
        """ëŒ€í™” ë‚´ìš© ë¶„ì„"""
        prompt = f"""
ë‹¤ìŒ ë…ê±°ë…¸ì¸ê³¼ AIì˜ ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì£¼ìš” ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ëŒ€í™” ë‚´ìš©:
{conversation}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "summary": "<í•œ ë¬¸ì¥ ìš”ì•½>",
    "main_topics": ["<ì£¼ì œ1>", "<ì£¼ì œ2>", ...],
    "daily_activities": ["<í™œë™1>", "<í™œë™2>", ...],
    "social_interactions": ["<ì‚¬íšŒí™œë™1>", "<ì‚¬íšŒí™œë™2>", ...],
    "health_mentions": ["<ê±´ê°• ê´€ë ¨ ì–¸ê¸‰1>", "<ê±´ê°• ê´€ë ¨ ì–¸ê¸‰2>", ...],
    "mood_indicators": ["<ê¸°ë¶„ ì§€í‘œ1>", "<ê¸°ë¶„ ì§€í‘œ2>", ...]
}}
"""
        
        try:
            response = await self._call_openai(prompt, max_tokens=600, task_name="analyze_conversation_content")
            data = json.loads(response)
            return ContentAnalysis.model_validate(data)
        except (json.JSONDecodeError, ValidationError) as exc:
            logger.error("Failed to parse conversation analysis response: %s", exc)
            return ContentAnalysis(
                summary="ë¶„ì„ ì‹¤íŒ¨",
                main_topics=[],
                daily_activities=[],
                social_interactions=[],
                health_mentions=[],
                mood_indicators=[]
            )
    
    async def detect_risk_keywords(self, conversation: str, image_analysis: Optional[Dict] = None) -> RiskAnalysis:
        """ìœ„í—˜ í‚¤ì›Œë“œ ê°ì§€ (ëŒ€í™” + ì´ë¯¸ì§€ ë¶„ì„ ì¢…í•©)"""
        
        # ì´ë¯¸ì§€ ë¶„ì„ì—ì„œ ìš°ë ¤ì‚¬í•­ ì¶”ì¶œ
        image_context = ""
        if image_analysis and "analysis" in image_analysis:
            img_data = image_analysis["analysis"]
            concerns = img_data.get("concerns", [])
            emotions = img_data.get("emotion", [])
            
            if concerns or any(emotion in ["ìŠ¬í””", "ë¬´ê¸°ë ¥í•¨"] for emotion in emotions):
                image_context = f"""

ì´ë¯¸ì§€ ë¶„ì„ì—ì„œ ê°ì§€ëœ ìš°ë ¤ì‚¬í•­:
- ê°ì • ìƒíƒœ: {", ".join(emotions)}
- ìš°ë ¤ì‚¬í•­: {", ".join(concerns) if concerns else "ì—†ìŒ"}
"""
        
        prompt = f"""
ë‹¤ìŒ ë…ê±°ë…¸ì¸ê³¼ AIì˜ ëŒ€í™”ì—ì„œ ìœ„í—˜ ì‹ í˜¸ë‚˜ ì£¼ì˜ê°€ í•„ìš”í•œ í‚¤ì›Œë“œë¥¼ ê°ì§€í•´ì£¼ì„¸ìš”.

ëŒ€í™” ë‚´ìš©:
{conversation}
{image_context}

ìœ„ ëŒ€í™” ë‚´ìš©ê³¼ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "risk_level": "<ê¸´ê¸‰/ì£¼ì˜/ë³´í†µ/ì•ˆì „>",
    "detected_keywords": ["<ìœ„í—˜í‚¤ì›Œë“œ1>", "<ìœ„í—˜í‚¤ì›Œë“œ2>", ...],
    "risk_categories": {{
        "health": ["<ê±´ê°• ìœ„í—˜ ìš”ì†Œ>", ...],
        "safety": ["<ì•ˆì „ ìœ„í—˜ ìš”ì†Œ>", ...],
        "mental": ["<ì •ì‹  ê±´ê°• ìœ„í—˜ ìš”ì†Œ>", ...],
        "social": ["<ì‚¬íšŒì  ìœ„í—˜ ìš”ì†Œ>", ...]
    }},
    "immediate_concerns": ["<ì¦‰ì‹œ í™•ì¸ í•„ìš” ì‚¬í•­>", ...],
    "recommended_actions": ["<ê¶Œì¥ ì¡°ì¹˜1>", "<ê¶Œì¥ ì¡°ì¹˜2>", ...]
}}

ìœ„í—˜ í‚¤ì›Œë“œ ì˜ˆì‹œ: ë„˜ì–´ì¡Œì–´ìš”, ì•„íŒŒìš”, ë°¥ì„ ëª» ë¨¹ì—ˆì–´ìš”, ì–´ì§€ëŸ¬ì›Œìš”, ìˆ¨ì´ ì°¨ìš”, í˜¼ì ë¬´ì„œì›Œìš” ë“±
ì´ë¯¸ì§€ì—ì„œ "ìš°ìš¸ì¦ ìš°ë ¤", "ìì‚´ ìœ„í—˜ ì˜ì‹¬" ë“±ì´ ê°ì§€ë˜ë©´ ë°˜ë“œì‹œ mental ì¹´í…Œê³ ë¦¬ì— í¬í•¨í•˜ì„¸ìš”.
"""
        
        try:
            response = await self._call_openai(prompt, max_tokens=700, task_name="detect_risk_keywords")
            data = json.loads(response)
            return RiskAnalysis.model_validate(data)
        except (json.JSONDecodeError, ValidationError) as exc:
            logger.error("Failed to parse risk analysis response: %s", exc)
            from app.models.analysis_models import RiskCategories
            return RiskAnalysis(
                risk_level="ë³´í†µ",
                detected_keywords=[],
                risk_categories=RiskCategories(),
                immediate_concerns=[],
                recommended_actions=[]
            )
    
    def calculate_baseline_comparisons(
        self,
        current_emotion: EmotionAnalysis,
        historical_data: Optional[List[Dict]] = None
    ) -> List[BaselineComparison]:
        """ê°œì¸ baseline ë¹„êµ ê³„ì‚° (7ì¼ í‰ê·  ëŒ€ë¹„, ë”ë¯¸ ë°ì´í„° í¬í•¨)"""
        # historical_dataê°€ ì—†ê±°ë‚˜ ë¶€ì¡±í•˜ë©´ ë”ë¯¸ ë°ì´í„° ìƒì„± (7ì¼)
        if not historical_data or len(historical_data) < 7:
            # ë”ë¯¸ ë°ì´í„° ìƒì„±: í˜„ì¬ ê°’ ê¸°ì¤€ìœ¼ë¡œ ì•½ê°„ì˜ ë³€ë™ì„± ì¶”ê°€
            import random
            random.seed(42)  # ì¬í˜„ ê°€ëŠ¥í•˜ë„ë¡
            
            historical_data = []
            base_positive = current_emotion.positive
            base_depression = current_emotion.depression
            base_loneliness = current_emotion.loneliness
            
            for i in range(7):
                # í˜„ì¬ ê°’ ê¸°ì¤€ Â±15 ë²”ìœ„ë¡œ ë³€ë™
                historical_data.append({
                    "positive": max(0, min(100, base_positive + random.randint(-15, 15))),
                    "depression": max(0, min(100, base_depression + random.randint(-15, 15))),
                    "loneliness": max(0, min(100, base_loneliness + random.randint(-15, 15))),
                    "overall_mood": "ë³´í†µ"
                })
        
        if len(historical_data) < 3:
            return []  # ìµœì†Œ 3ì¼ì€ í•„ìš”
        
        # ìµœê·¼ 7ì¼ ë°ì´í„°ë§Œ ì‚¬ìš©
        recent_data = historical_data[-7:]
        
        # ê° ì§€í‘œë³„ baseline ê³„ì‚°
        comparisons = []
        
        # ê¸ì • ì ìˆ˜ ë¹„êµ
        baseline_positive = sum(d.get("positive", 50) for d in recent_data) / len(recent_data)
        diff_positive = current_emotion.positive - baseline_positive
        diff_pct_positive = (diff_positive / baseline_positive * 100) if baseline_positive > 0 else 0
        
        comparisons.append(BaselineComparison(
            comparison_period="ì§€ë‚œ 7ì¼",
            metric="ê¸ì • ê°ì •",
            current_value=float(current_emotion.positive),
            baseline_average=baseline_positive,
            difference=diff_positive,
            difference_percentage=diff_pct_positive,
            is_significant_change=abs(diff_pct_positive) > 20,  # 20% ì´ìƒ ë³€í™” ì‹œ ìœ ì˜ë¯¸
            explanation=f"í‰ì†Œ í‰ê·  {baseline_positive:.1f}ì  ëŒ€ë¹„ {diff_positive:+.1f}ì  ({diff_pct_positive:+.1f}%)"
        ))
        
        # ìš°ìš¸ ì ìˆ˜ ë¹„êµ
        baseline_depression = sum(d.get("depression", 50) for d in recent_data) / len(recent_data)
        diff_depression = current_emotion.depression - baseline_depression
        diff_pct_depression = (diff_depression / baseline_depression * 100) if baseline_depression > 0 else 0
        
        comparisons.append(BaselineComparison(
            comparison_period="ì§€ë‚œ 7ì¼",
            metric="ìš°ìš¸ ê°ì •",
            current_value=float(current_emotion.depression),
            baseline_average=baseline_depression,
            difference=diff_depression,
            difference_percentage=diff_pct_depression,
            is_significant_change=abs(diff_pct_depression) > 20,
            explanation=f"í‰ì†Œ í‰ê·  {baseline_depression:.1f}ì  ëŒ€ë¹„ {diff_depression:+.1f}ì  ({diff_pct_depression:+.1f}%)"
        ))
        
        # ì™¸ë¡œì›€ ì ìˆ˜ ë¹„êµ
        baseline_loneliness = sum(d.get("loneliness", 50) for d in recent_data) / len(recent_data)
        diff_loneliness = current_emotion.loneliness - baseline_loneliness
        diff_pct_loneliness = (diff_loneliness / baseline_loneliness * 100) if baseline_loneliness > 0 else 0
        
        comparisons.append(BaselineComparison(
            comparison_period="ì§€ë‚œ 7ì¼",
            metric="ì™¸ë¡œì›€ ê°ì •",
            current_value=float(current_emotion.loneliness),
            baseline_average=baseline_loneliness,
            difference=diff_loneliness,
            difference_percentage=diff_pct_loneliness,
            is_significant_change=abs(diff_pct_loneliness) > 20,
            explanation=f"í‰ì†Œ í‰ê·  {baseline_loneliness:.1f}ì  ëŒ€ë¹„ {diff_loneliness:+.1f}ì  ({diff_pct_loneliness:+.1f}%)"
        ))
        
        return comparisons
    
    async def detect_anomaly_patterns(self, conversation: str, historical_data: Optional[List[Dict]] = None) -> AnomalyAnalysis:
        """ì´ìƒ íŒ¨í„´ ê°ì§€ (ê³¼ê±° ë°ì´í„°ì™€ ë¹„êµ) + baseline ë¹„êµ í¬í•¨"""
        historical_context = ""
        if historical_data:
            recent_moods = [data.get("overall_mood", "ë³´í†µ") for data in historical_data[-7:]]  # ìµœê·¼ 7ì¼
            historical_context = f"\nìµœê·¼ ì¼ì£¼ì¼ ê¸°ë¶„ ë³€í™”: {' -> '.join(recent_moods)}"
        
        prompt = f"""
ë‹¤ìŒ ë…ê±°ë…¸ì¸ì˜ ì˜¤ëŠ˜ ëŒ€í™”ì™€ ê³¼ê±° ë°ì´í„°ë¥¼ ë¹„êµí•˜ì—¬ ì´ìƒ íŒ¨í„´ì„ ê°ì§€í•´ì£¼ì„¸ìš”.

ì˜¤ëŠ˜ ëŒ€í™”:
{conversation}

{historical_context}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "pattern_detected": <true/false>,
    "pattern_type": "<ê¸‰ê²©í•œí•˜ë½/ì§€ì†ì í•˜ë½/í–‰ë™ë³€í™”/ì–¸ì–´íŒ¨í„´ë³€í™”/ì—†ìŒ>",
    "severity": "<ì‹¬ê°/ë³´í†µ/ê²½ë¯¸>",
    "trend_analysis": "<íŒ¨í„´ ë¶„ì„ ì„¤ëª…>",
    "comparison_notes": "<ê³¼ê±° ëŒ€ë¹„ ë³€í™” ì„¤ëª…>",
    "alert_needed": <true/false>,
    "monitoring_recommendations": ["<ëª¨ë‹ˆí„°ë§ ê¶Œì¥ì‚¬í•­1>", ...]
}}

ì£¼ì˜: alert_neededëŠ” ì •ë§ ì‹¬ê°í•œ ê²½ìš°ì—ë§Œ trueë¡œ ì„¤ì •í•˜ì„¸ìš”. ê²½ë¯¸í•œ ë³€í™”ëŠ” falseë¡œ ì„¤ì •í•˜ì—¬ ë¶ˆí•„ìš”í•œ ë¶ˆì•ˆì„ ìœ ë°œí•˜ì§€ ë§ˆì„¸ìš”.
"""
        
        try:
            response = await self._call_openai(prompt, max_tokens=500, task_name="detect_anomaly_patterns")
            data = json.loads(response)
            
            anomaly = AnomalyAnalysis.model_validate(data)
            # baseline ë¹„êµëŠ” ë‚˜ì¤‘ì— ì¶”ê°€ë¨ (analyze_video_letter_comprehensiveì—ì„œ)
            return anomaly
        except (json.JSONDecodeError, ValidationError) as exc:
            logger.error("Failed to parse anomaly analysis response: %s", exc)
            return AnomalyAnalysis(
                pattern_detected=False,
                pattern_type="ì—†ìŒ",
                severity="ê²½ë¯¸",
                trend_analysis="ë¶„ì„ ì‹¤íŒ¨",
                comparison_notes="ê³¼ê±° ë°ì´í„° ë¶€ì¡±",
                alert_needed=False,
                monitoring_recommendations=[],
                baseline_comparisons=[]
            )
    
    async def analyze_video_letter_comprehensive(
        self, 
        conversation: str, 
        historical_data: Optional[List[Dict]] = None,
        image_analysis: Optional[Dict] = None
    ) -> ComprehensiveAnalysisResult:
        """ì˜ìƒ í¸ì§€ ì¢…í•© ë¶„ì„ (ë³‘ë ¬ ì²˜ë¦¬, íƒ€ì„ì•„ì›ƒ ìµœì í™”)"""
        print(f"[PERF] Starting analyze_video_letter_comprehensive (4 parallel tasks)", flush=True)
        logger.info("[PERF] Starting analyze_video_letter_comprehensive (4 parallel tasks)")
        parallel_start = time.time()
        
        # ê° ì‘ì—…ì— ê°œë³„ íƒ€ì„ì•„ì›ƒ ì ìš© (15ì´ˆ)
        async def emotion_with_timeout():
            try:
                return await asyncio.wait_for(
                    self.analyze_emotion_state(conversation, image_analysis),
                    timeout=15.0
                )
            except (asyncio.TimeoutError, Exception) as exc:
                logger.error(f"Emotion analysis failed/timeout: {exc}")
                return EmotionAnalysis(
                    positive=50, negative=50, anxiety=50, depression=50, loneliness=50,
                    overall_mood="ë³´í†µ", emotional_summary="ë¶„ì„ ì‹¤íŒ¨"
                )
        
        async def content_with_timeout():
            try:
                return await asyncio.wait_for(
                    self.analyze_conversation_content(conversation),
                    timeout=15.0
                )
            except (asyncio.TimeoutError, Exception) as exc:
                logger.error(f"Content analysis failed/timeout: {exc}")
                return ContentAnalysis(summary="ë¶„ì„ ì‹¤íŒ¨")
        
        async def risk_with_timeout():
            try:
                return await asyncio.wait_for(
                    self.detect_risk_keywords(conversation, image_analysis),
                    timeout=15.0
                )
            except (asyncio.TimeoutError, Exception) as exc:
                logger.error(f"Risk analysis failed/timeout: {exc}")
                from app.models.analysis_models import RiskCategories
                return RiskAnalysis(
                    risk_level="ë³´í†µ", detected_keywords=[], 
                    risk_categories=RiskCategories()
                )
        
        async def anomaly_with_timeout():
            try:
                return await asyncio.wait_for(
                    self.detect_anomaly_patterns(conversation, historical_data),
                    timeout=15.0
                )
            except (asyncio.TimeoutError, Exception) as exc:
                logger.error(f"Anomaly analysis failed/timeout: {exc}")
                return AnomalyAnalysis(
                    pattern_detected=False, pattern_type="ì—†ìŒ", severity="ê²½ë¯¸",
                    trend_analysis="ë¶„ì„ ì‹¤íŒ¨", comparison_notes="ê³¼ê±° ë°ì´í„° ë¶€ì¡±",
                    alert_needed=False
                )
        
        try:
            # ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ ë³‘ë ¬ë¡œ ê¸°ë‹¤ë¦¼ (ê°ê° ìµœëŒ€ 15ì´ˆ)
            emotion_result, content_result, risk_result, anomaly_result = await asyncio.gather(
                emotion_with_timeout(),
                content_with_timeout(),
                risk_with_timeout(),
                anomaly_with_timeout(),
                return_exceptions=False  # ì´ë¯¸ íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ë¨
            )
            parallel_time = time.time() - parallel_start
            print(f"[PERF] Parallel analysis completed in {parallel_time:.2f}s", flush=True)
            logger.info(f"[PERF] Parallel analysis completed in {parallel_time:.2f}s")
            
            # baseline ë¹„êµ ê³„ì‚° (historical_dataê°€ ìˆëŠ” ê²½ìš°)
            baseline_comparisons = []
            if historical_data:
                baseline_comparisons = self.calculate_baseline_comparisons(emotion_result, historical_data)
                anomaly_result.baseline_comparisons = baseline_comparisons
            
            # ì¢…í•© ë¶„ì„ ê²°ê³¼ ìƒì„±
            comprehensive_result = self._generate_comprehensive_summary(
                emotion_result, content_result, risk_result, anomaly_result
            )
            
            return ComprehensiveAnalysisResult(
                timestamp=datetime.now().isoformat(),
                emotion_analysis=emotion_result,
                content_analysis=content_result,
                risk_analysis=risk_result,
                anomaly_analysis=anomaly_result,
                comprehensive_summary=comprehensive_result
            )
            
        except Exception as exc:
            logger.error("Comprehensive analysis failed: %s", exc)
            raise RuntimeError("ì˜ìƒ í¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.") from exc
    
    def _generate_comprehensive_summary(
        self, 
        emotion: EmotionAnalysis, 
        content: ContentAnalysis, 
        risk: RiskAnalysis, 
        anomaly: AnomalyAnalysis
    ) -> ComprehensiveSummary:
        """ì¢…í•© ë¶„ì„ ê²°ê³¼ ìš”ì•½ ìƒì„±"""
        
        # ì „ë°˜ì  ìƒíƒœ íŒì •
        overall_status = "ğŸ˜Š ì¢‹ìŒ"
        if risk.risk_level == "ê¸´ê¸‰" or anomaly.alert_needed:
            overall_status = "ğŸš¨ ê¸´ê¸‰"
        elif risk.risk_level == "ì£¼ì˜" or emotion.overall_mood in ["ë‚˜ì¨", "ë§¤ìš°ë‚˜ì¨"]:
            overall_status = "ğŸ˜Ÿ ì£¼ì˜"
        elif emotion.overall_mood == "ë³´í†µ":
            overall_status = "ğŸ˜ ë³´í†µ"
        
        # ì•Œë¦¼ ì—¬ë¶€ ê²°ì • (ê³¼ë„í•œ ê²½ê³  ë°©ì§€)
        # baseline ë¹„êµê°€ ìˆìœ¼ë©´, ìœ ì˜ë¯¸í•œ ë³€í™”ê°€ ìˆì„ ë•Œë§Œ alert
        is_significant_change = False
        if anomaly.baseline_comparisons:
            is_significant_change = any(comp.is_significant_change for comp in anomaly.baseline_comparisons)
        
        # alertëŠ” ì •ë§ ì‹¬ê°í•œ ê²½ìš°ì—ë§Œ (ê³¼ë„í•œ ê²½ê³  ë°©ì§€)
        alert_needed = (
            risk.risk_level == "ê¸´ê¸‰" or  # ê¸´ê¸‰ë§Œ ìë™ alert
            (risk.risk_level == "ì£¼ì˜" and is_significant_change) or  # ì£¼ì˜ëŠ” baseline ë³€í™”ê°€ ìˆì„ ë•Œë§Œ
            (anomaly.alert_needed and anomaly.severity == "ì‹¬ê°")  # ì‹¬ê°í•œ ì´ìƒ íŒ¨í„´ë§Œ
        )
        
        # ê¶Œì¥ ì¡°ì¹˜ í†µí•©
        all_actions = []
        all_actions.extend(risk.recommended_actions)
        all_actions.extend(anomaly.monitoring_recommendations)
        
        if not all_actions:
            if overall_status == "ğŸ˜Š ì¢‹ìŒ":
                all_actions = ["í˜„ì¬ ìƒíƒœ ì–‘í˜¸, ì •ê¸° í™•ì¸ ìœ ì§€"]
            else:
                all_actions = ["ìƒíƒœ ë³€í™” ëª¨ë‹ˆí„°ë§ í•„ìš”"]
        
        return ComprehensiveSummary(
            overall_status=overall_status,
            status_emoji=overall_status.split()[0],
            status_text=overall_status.split()[1],
            alert_needed=alert_needed,
            priority_level=risk.risk_level,
            main_summary=content.summary,
            emotion_score=EmotionScore(
                positive=emotion.positive,
                anxiety=emotion.anxiety,
                depression=emotion.depression
            ),
            key_concerns=risk.immediate_concerns,
            recommended_actions=all_actions[:3],  # ìµœëŒ€ 3ê°œë§Œ
            requires_immediate_attention=risk.risk_level == "ê¸´ê¸‰"
        )
    
    async def close(self):
        """í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬"""
        if self._client:
            await self._client.aclose()